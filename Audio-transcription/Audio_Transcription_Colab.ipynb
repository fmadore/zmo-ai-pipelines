{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a95d729",
   "metadata": {},
   "source": [
    "## Step 1: Setup (Run this first!) ‚öôÔ∏è\n",
    "\n",
    "Click the ‚ñ∂Ô∏è button to install the required software. This may take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-genai pydub ipywidgets\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydub import AudioSegment\n",
    "\n",
    "print(\"‚úÖ Setup complete! You can proceed to the next step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a52a50",
   "metadata": {},
   "source": [
    "## Step 2: Enter Your API Key üîë\n",
    "\n",
    "Enter your Google Gemini API key below. \n",
    "\n",
    "**Don't have one?** Get it free at: https://aistudio.google.com/app/api-keys\n",
    "\n",
    "Your API key is entered securely (hidden like a password)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a secure password field for the API key\n",
    "api_key_input = widgets.Password(\n",
    "    placeholder='Paste your API key here',\n",
    "    description='API Key:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '80px'}\n",
    ")\n",
    "\n",
    "api_key_status = widgets.HTML(value=\"\")\n",
    "\n",
    "def validate_api_key(change):\n",
    "    if len(change['new']) > 20:\n",
    "        api_key_status.value = \"<span style='color: green;'>‚úÖ API key entered</span>\"\n",
    "    else:\n",
    "        api_key_status.value = \"<span style='color: orange;'>‚è≥ Please enter your full API key</span>\"\n",
    "\n",
    "api_key_input.observe(validate_api_key, names='value')\n",
    "\n",
    "display(HTML(\"<b>Enter your Gemini API key:</b>\"))\n",
    "display(api_key_input)\n",
    "display(api_key_status)\n",
    "display(HTML(\"<br><i>üí° Tip: Your key starts with 'AIza...'</i>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc9d26",
   "metadata": {},
   "source": [
    "## Step 3: Upload Your Audio File(s) üìÅ\n",
    "\n",
    "Click the button below to select and upload your audio file(s).\n",
    "\n",
    "**Supported formats:** MP3, WAV, M4A, FLAC, OGG, WEBM, MP4, AAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store uploaded files\n",
    "uploaded_files = []\n",
    "\n",
    "# Supported formats\n",
    "SUPPORTED_FORMATS = {\n",
    "    '.mp3': 'audio/mpeg',\n",
    "    '.wav': 'audio/wav',\n",
    "    '.m4a': 'audio/mp4',\n",
    "    '.flac': 'audio/flac',\n",
    "    '.ogg': 'audio/ogg',\n",
    "    '.webm': 'audio/webm',\n",
    "    '.mp4': 'audio/mp4',\n",
    "    '.aac': 'audio/aac'\n",
    "}\n",
    "\n",
    "upload_status = widgets.HTML(value=\"\")\n",
    "\n",
    "def upload_audio_files(b):\n",
    "    global uploaded_files\n",
    "    upload_status.value = \"<span style='color: blue;'>üì§ Upload dialog opened... Select your file(s)</span>\"\n",
    "    \n",
    "    try:\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if uploaded:\n",
    "            uploaded_files = []\n",
    "            valid_files = []\n",
    "            invalid_files = []\n",
    "            \n",
    "            for filename, content in uploaded.items():\n",
    "                ext = Path(filename).suffix.lower()\n",
    "                if ext in SUPPORTED_FORMATS:\n",
    "                    # Save file locally in Colab\n",
    "                    with open(filename, 'wb') as f:\n",
    "                        f.write(content)\n",
    "                    uploaded_files.append(filename)\n",
    "                    valid_files.append(filename)\n",
    "                else:\n",
    "                    invalid_files.append(filename)\n",
    "            \n",
    "            status_html = \"\"\n",
    "            if valid_files:\n",
    "                status_html += f\"<span style='color: green;'>‚úÖ Uploaded {len(valid_files)} audio file(s):</span><br>\"\n",
    "                for f in valid_files:\n",
    "                    status_html += f\"&nbsp;&nbsp;&nbsp;üìÑ {f}<br>\"\n",
    "            if invalid_files:\n",
    "                status_html += f\"<span style='color: red;'>‚ùå Skipped {len(invalid_files)} unsupported file(s):</span><br>\"\n",
    "                for f in invalid_files:\n",
    "                    status_html += f\"&nbsp;&nbsp;&nbsp;‚ö†Ô∏è {f}<br>\"\n",
    "            \n",
    "            upload_status.value = status_html\n",
    "        else:\n",
    "            upload_status.value = \"<span style='color: orange;'>‚ö†Ô∏è No files uploaded</span>\"\n",
    "    except Exception as e:\n",
    "        upload_status.value = f\"<span style='color: red;'>‚ùå Error: {str(e)}</span>\"\n",
    "\n",
    "upload_button = widgets.Button(\n",
    "    description='üìÅ Click to Upload Audio Files',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "upload_button.on_click(upload_audio_files)\n",
    "\n",
    "display(upload_button)\n",
    "display(upload_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43dd50b",
   "metadata": {},
   "source": [
    "## Step 4: Choose Your Settings üéõÔ∏è\n",
    "\n",
    "Select the transcription style and options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aff251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PROMPT DEFINITIONS\n",
    "# ============================================\n",
    "\n",
    "PROMPTS = {\n",
    "    \"1. Full Audio Transcription\": {\n",
    "        \"description\": \"Detailed word-for-word transcription with timestamps and speaker labels\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Full audio transcription\n",
    "\n",
    "## Role and Objective\n",
    "- Faithfully transcribe audio recordings into a publication-ready, accurate, and well-structured transcript.\n",
    "\n",
    "## Instructions\n",
    "- Transcribe exactly what is spoken without summarising or paraphrasing.\n",
    "- Use standard punctuation and sentence case; break into paragraphs at topic or speaker shifts.\n",
    "- Label each speaker consistently as Speaker 1:, Speaker 2:, etc.\n",
    "- Insert a timestamp at the start of every speaker turn in the format [hh:mm:ss].\n",
    "- For unclear audio, use [inaudible hh:mm:ss]. If unsure about a word or name, bracket with a question mark, e.g., [Kandahar?].\n",
    "- Mark non-speech events (e.g., [overlapping speech], [laughter], [applause], [music]) in square brackets.\n",
    "- Omit routine filler words (\"um\", \"uh\", repeated false starts) unless their inclusion changes the meaning of the sentence.\n",
    "- Normalize numbers and dates for clarity (e.g., \"twenty-five\" ‚Üí \"25\", \"first of May 2024\" ‚Üí \"1 May 2024\").\n",
    "- Preserve names and terms as heard; if unsure of spelling, use [term?].\n",
    "- Maintain any code-switching or language changes as spoken; do not translate.\n",
    "- Transcribe profanity, slurs, and sensitive language exactly as spoken.\n",
    "- After completing the transcription, validate the output to ensure it matches the defined formatting conventions and is free of omissions, correcting any errors identified before finalizing the output.\n",
    "\n",
    "### Output Format\n",
    "- Each speaker turn starts on a new line with a timestamp [hh:mm:ss], speaker label, and the transcript.\n",
    "- Clearly indicate non-speech and unclear audio using the conventions above.\n",
    "- Separate paragraphs (speaker turns or topic shifts) with a blank line.\n",
    "- Output should be in plain text or Markdown with appropriate spacing.\"\"\"\n",
    "    },\n",
    "    \"2. Meeting Minutes\": {\n",
    "        \"description\": \"Summarized meeting notes with decisions, action items, and next steps\",\n",
    "        \"auto_split\": False,\n",
    "        \"content\": \"\"\"# Minutes Meeting\n",
    "\n",
    "## Role and Objective\n",
    "- Generate succinct, decision-oriented meeting minutes focused on actionable outcomes and relevant context.\n",
    "\n",
    "## Instructions\n",
    "- Summarize, do not transcribe. Capture only essential information for clarity and accountability.\n",
    "\n",
    "### Scope\n",
    "- Include:\n",
    "  - Header details (title, date/time, location, chair, note-taker, attendees, apologies)\n",
    "  - Agenda coverage\n",
    "  - Announcements\n",
    "  - Decisions\n",
    "  - Action items (specifying owner and due date)\n",
    "  - Key risks/issues\n",
    "  - Dependencies\n",
    "  - Open questions\n",
    "  - Next steps/next meeting\n",
    "- Maintain only the context necessary to understand each decision, with brief rationale. Omit small talk and verbatim digressions.\n",
    "\n",
    "### Participants & Timing\n",
    "- List all attendees, apologies, chair, and note-taker.\n",
    "- Add a `[hh:mm:ss]` timestamp at the start of any decision, action, or announcement if available in the input.\n",
    "\n",
    "### Editing Rules\n",
    "- Capture the core point, not all rhetoric; avoid unintended paraphrasing or misrepresentation.\n",
    "- Normalize numbers and dates (e.g., 15 September 2025, 14:00‚Äì15:00 CEST).\n",
    "- Use consistent speaker names/roles. If unknown, default to \"Participant 1\", \"Participant 2\", etc.\n",
    "- For unclear audio, insert `[inaudible hh:mm:ss]`; for overlapping speakers, insert `[crosstalk]`.\n",
    "- If any action item is missing an owner or deadline, set as Owner: TBD / Due: TBD and flag this instance.\"\"\"\n",
    "    },\n",
    "    \"3. Interview Transcription\": {\n",
    "        \"description\": \"Q&A format with interviewer/interviewee labels and emotional context\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Interview Transcription Prompt\n",
    "\n",
    "Please transcribe this interview accurately.\n",
    "- Clearly distinguish between interviewer and interviewee\n",
    "- Format in a question-and-answer structure when possible\n",
    "- Include emotional context (laughter, pauses) in [brackets]\n",
    "- Maintain the conversational flow and natural speech patterns\n",
    "- Preserve the tone and style of both speakers\n",
    "- Note any significant pauses or interruptions\n",
    "- Keep the chronological order of the conversation\"\"\"\n",
    "    },\n",
    "    \"4. Lecture/Educational Content\": {\n",
    "        \"description\": \"Structured notes with key concepts, definitions, and Q&A sections\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Lecture\n",
    "\n",
    "Transcribe the educational content accurately, focusing strictly on the key concepts and main points. Structure the transcript in clear paragraphs, only including slide references or visual descriptions when explicitly mentioned in the material. Note audience questions and responses in a separate section. Preserve all academic terminology and technical language precisely; do not simplify unless specifically requested. Organize the material logically for educational clarity, and highlight major concepts and definitions.\n",
    "\n",
    "Extract only the central ideas and supporting points emphasized by the speaker, such as the thesis, key claims, evidence/examples, methodologies, conclusions, and implications or limitations.\n",
    "\n",
    "Output format:\n",
    "# Summary (‚â§ 200 words)\n",
    "## Core Takeaways (5-8 bullets)\n",
    "## Key Points by Section\n",
    "## Definitions & Concepts\n",
    "## Evidence & Examples\n",
    "## Q&A (if any)\n",
    "## Keywords/Tags\"\"\"\n",
    "    },\n",
    "    \"5. Q&A Summary\": {\n",
    "        \"description\": \"Extract and condense only questions and answers from recordings\",\n",
    "        \"auto_split\": False,\n",
    "        \"content\": \"\"\"# Q&A-Focused Transcription (Extract & Condense)\n",
    "\n",
    "## Role and Objective\n",
    "Produce a concise Q&A transcript from audio recordings by extracting and condensing only the essential questions and answers.\n",
    "\n",
    "## Instructions\n",
    "- Include only questions and answers in the transcript.\n",
    "- Omit introductions, bios, housekeeping comments, and small talk.\n",
    "- For each question, summarize to the essential inquiry in 1‚Äì2 sentences, retaining key names, citations, numbers, and dates.\n",
    "- For each answer, distill the main claim(s) and provide up to 3‚Äì4 supporting points or examples.\n",
    "\n",
    "## Speakers & Timestamps\n",
    "- Label each turn as: `[hh:mm:ss] Q (Name/Audience #):` and `[hh:mm:ss] A (Name/Role):`\n",
    "- If the speaker is unnamed, use Audience 1, Audience 2, etc.\n",
    "\n",
    "## Output Format\n",
    "- Output must be strictly in Markdown.\n",
    "- Each Q and A block appears on its own line.\n",
    "- Insert a single blank line between each Q/A pair.\"\"\"\n",
    "    },\n",
    "    \"6. Full Audio Translation (to English)\": {\n",
    "        \"description\": \"Translate non-English audio to English with cultural context notes\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Full audio translation (to English)\n",
    "\n",
    "## Role and Objective\n",
    "- Faithfully transcribe and translate audio recordings into a publication-ready, accurate, and well-structured English transcript.\n",
    "\n",
    "## Instructions\n",
    "- Translate all spoken content into English, regardless of the original language(s).\n",
    "- Maintain the original meaning and tone as closely as possible while producing natural, fluent English.\n",
    "- Use standard punctuation and sentence case; break into paragraphs at topic or speaker shifts.\n",
    "- Label each speaker consistently as Speaker 1:, Speaker 2:, etc.\n",
    "- Insert a timestamp at the start of every speaker turn in the format [hh:mm:ss].\n",
    "- For unclear audio, use [inaudible hh:mm:ss]. If unsure about a word or name, bracket with a question mark, e.g., [Kandahar?].\n",
    "- Mark non-speech events (e.g., [overlapping speech], [laughter], [applause], [music]) in square brackets.\n",
    "- When the original language changes (code-switching), indicate the original language in brackets, e.g., [in French:] before the translated text if relevant for context.\n",
    "- For culturally specific terms, idiomatic expressions, or words with no direct English equivalent, provide the English translation followed by the original term in parentheses, e.g., \"religious endowment (waqf)\", \"neighborhood (mahalla)\".\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# SETTINGS WIDGETS\n",
    "# ============================================\n",
    "\n",
    "# Model selection\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Gemini 2.5 Pro (High quality, balanced)', 'gemini-2.5-pro'),\n",
    "        ('Gemini 2.5 Flash (Faster, good quality)', 'gemini-2.5-flash'),\n",
    "        ('Gemini 2.0 Flash (Latest fast model)', 'gemini-2.0-flash'),\n",
    "    ],\n",
    "    value='gemini-2.5-pro',\n",
    "    description='AI Model:',\n",
    "    style={'description_width': '100px'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Prompt selection\n",
    "prompt_dropdown = widgets.Dropdown(\n",
    "    options=list(PROMPTS.keys()),\n",
    "    value='1. Full Audio Transcription',\n",
    "    description='Style:',\n",
    "    style={'description_width': '100px'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Prompt description display\n",
    "prompt_description = widgets.HTML(\n",
    "    value=f\"<i>üìù {PROMPTS['1. Full Audio Transcription']['description']}</i>\"\n",
    ")\n",
    "\n",
    "def update_prompt_description(change):\n",
    "    selected = change['new']\n",
    "    desc = PROMPTS[selected]['description']\n",
    "    auto_split = PROMPTS[selected]['auto_split']\n",
    "    prompt_description.value = f\"<i>üìù {desc}</i>\"\n",
    "    # Update split checkbox based on prompt recommendation\n",
    "    split_checkbox.value = auto_split\n",
    "\n",
    "prompt_dropdown.observe(update_prompt_description, names='value')\n",
    "\n",
    "# Audio splitting options\n",
    "split_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Split long audio files into segments (recommended for files > 10 min)',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "segment_slider = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=5,\n",
    "    max=30,\n",
    "    step=5,\n",
    "    description='Segment length (minutes):',\n",
    "    style={'description_width': '180px'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Custom prompt option\n",
    "use_custom_prompt = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Use custom prompt instead',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "custom_prompt_text = widgets.Textarea(\n",
    "    placeholder='Enter your custom transcription instructions here...\\n\\nExample: Please transcribe this audio in French, focusing on technical terminology.',\n",
    "    layout=widgets.Layout(width='500px', height='150px'),\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "def toggle_custom_prompt(change):\n",
    "    custom_prompt_text.disabled = not change['new']\n",
    "    prompt_dropdown.disabled = change['new']\n",
    "\n",
    "use_custom_prompt.observe(toggle_custom_prompt, names='value')\n",
    "\n",
    "# Display all settings\n",
    "display(HTML(\"<h3>ü§ñ Select AI Model</h3>\"))\n",
    "display(model_dropdown)\n",
    "\n",
    "display(HTML(\"<h3>üìã Select Transcription Style</h3>\"))\n",
    "display(prompt_dropdown)\n",
    "display(prompt_description)\n",
    "\n",
    "display(HTML(\"<br>\"))\n",
    "display(use_custom_prompt)\n",
    "display(custom_prompt_text)\n",
    "\n",
    "display(HTML(\"<h3>‚úÇÔ∏è Audio Splitting Options</h3>\"))\n",
    "display(split_checkbox)\n",
    "display(segment_slider)\n",
    "display(HTML(\"<i>üí° Splitting helps with long recordings and improves accuracy</i>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d5b7c",
   "metadata": {},
   "source": [
    "## Step 5: Start Transcription! üöÄ\n",
    "\n",
    "Click the button below to start transcribing your audio file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRANSCRIPTION ENGINE\n",
    "# ============================================\n",
    "\n",
    "class ColabAudioTranscriber:\n",
    "    \"\"\"Simplified Audio Transcriber for Google Colab.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key, model='gemini-2.5-pro'):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.client = genai.Client(api_key=self.api_key)\n",
    "        self.supported_formats = SUPPORTED_FORMATS\n",
    "    \n",
    "    def prepare_audio(self, audio_file_path):\n",
    "        \"\"\"Read audio file and determine MIME type.\"\"\"\n",
    "        with open(audio_file_path, 'rb') as f:\n",
    "            audio_bytes = f.read()\n",
    "        ext = Path(audio_file_path).suffix.lower()\n",
    "        mime_type = self.supported_formats.get(ext, 'audio/mpeg')\n",
    "        return audio_bytes, mime_type\n",
    "    \n",
    "    def split_audio(self, audio_file_path, segment_minutes=10):\n",
    "        \"\"\"Split audio into segments.\"\"\"\n",
    "        try:\n",
    "            segment_ms = segment_minutes * 60 * 1000\n",
    "            audio = AudioSegment.from_file(audio_file_path)\n",
    "            \n",
    "            if len(audio) <= segment_ms:\n",
    "                return [audio_file_path]\n",
    "            \n",
    "            segments = []\n",
    "            base_name = Path(audio_file_path).stem\n",
    "            ext = Path(audio_file_path).suffix\n",
    "            \n",
    "            for i, start in enumerate(range(0, len(audio), segment_ms), start=1):\n",
    "                end = min(start + segment_ms, len(audio))\n",
    "                chunk = audio[start:end]\n",
    "                segment_path = f\"{base_name}_segment_{i:02d}{ext}\"\n",
    "                \n",
    "                # Map extensions to export formats\n",
    "                format_map = {'m4a': 'mp4', 'mp4': 'mp4', 'mp3': 'mp3', \n",
    "                              'wav': 'wav', 'flac': 'flac', 'ogg': 'ogg'}\n",
    "                export_format = format_map.get(ext.lstrip('.').lower(), 'mp3')\n",
    "                chunk.export(segment_path, format=export_format)\n",
    "                segments.append(segment_path)\n",
    "            \n",
    "            return segments\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not split audio: {e}. Processing as single file.\")\n",
    "            return [audio_file_path]\n",
    "    \n",
    "    def transcribe(self, audio_file_path, prompt):\n",
    "        \"\"\"Transcribe a single audio file.\"\"\"\n",
    "        audio_bytes, mime_type = self.prepare_audio(audio_file_path)\n",
    "        \n",
    "        audio_part = types.Part.from_bytes(\n",
    "            data=audio_bytes,\n",
    "            mime_type=mime_type\n",
    "        )\n",
    "        \n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=[prompt, audio_part],\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.1,\n",
    "                max_output_tokens=65536,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return response.text.strip()\n",
    "\n",
    "# ============================================\n",
    "# TRANSCRIPTION BUTTON AND OUTPUT\n",
    "# ============================================\n",
    "\n",
    "output_area = widgets.Output()\n",
    "transcription_results = {}  # Store results for download\n",
    "\n",
    "def run_transcription(b):\n",
    "    global transcription_results\n",
    "    transcription_results = {}\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        # Validate inputs\n",
    "        if not api_key_input.value or len(api_key_input.value) < 20:\n",
    "            print(\"‚ùå Please enter a valid API key in Step 2\")\n",
    "            return\n",
    "        \n",
    "        if not uploaded_files:\n",
    "            print(\"‚ùå Please upload at least one audio file in Step 3\")\n",
    "            return\n",
    "        \n",
    "        # Get settings\n",
    "        api_key = api_key_input.value\n",
    "        model = model_dropdown.value\n",
    "        split_audio = split_checkbox.value\n",
    "        segment_minutes = segment_slider.value\n",
    "        \n",
    "        # Get prompt\n",
    "        if use_custom_prompt.value and custom_prompt_text.value.strip():\n",
    "            prompt = custom_prompt_text.value.strip()\n",
    "            print(\"üìù Using custom prompt\")\n",
    "        else:\n",
    "            selected_prompt = prompt_dropdown.value\n",
    "            prompt = PROMPTS[selected_prompt]['content']\n",
    "            print(f\"üìù Using: {selected_prompt}\")\n",
    "        \n",
    "        print(f\"ü§ñ Model: {model}\")\n",
    "        print(f\"‚úÇÔ∏è Audio splitting: {'Enabled' if split_audio else 'Disabled'}\")\n",
    "        if split_audio:\n",
    "            print(f\"   Segment length: {segment_minutes} minutes\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            # Initialize transcriber\n",
    "            transcriber = ColabAudioTranscriber(api_key, model)\n",
    "            print(\"‚úÖ Connected to Gemini API\\n\")\n",
    "            \n",
    "            # Process each file\n",
    "            for i, audio_file in enumerate(uploaded_files, 1):\n",
    "                print(f\"\\nüéµ Processing file {i}/{len(uploaded_files)}: {audio_file}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                try:\n",
    "                    if split_audio:\n",
    "                        segments = transcriber.split_audio(audio_file, segment_minutes)\n",
    "                        if len(segments) > 1:\n",
    "                            print(f\"‚úÇÔ∏è Split into {len(segments)} segments\")\n",
    "                        \n",
    "                        transcription_parts = []\n",
    "                        for j, segment in enumerate(segments, 1):\n",
    "                            print(f\"   ‚è≥ Transcribing segment {j}/{len(segments)}...\")\n",
    "                            result = transcriber.transcribe(segment, prompt)\n",
    "                            if len(segments) > 1:\n",
    "                                transcription_parts.append(f\"[Segment {j}]\\n{result}\")\n",
    "                            else:\n",
    "                                transcription_parts.append(result)\n",
    "                            print(f\"   ‚úÖ Segment {j} complete\")\n",
    "                        \n",
    "                        transcription = \"\\n\\n\".join(transcription_parts)\n",
    "                    else:\n",
    "                        print(\"   ‚è≥ Transcribing...\")\n",
    "                        transcription = transcriber.transcribe(audio_file, prompt)\n",
    "                    \n",
    "                    # Store result\n",
    "                    output_filename = Path(audio_file).stem + \"_transcription.txt\"\n",
    "                    transcription_results[output_filename] = transcription\n",
    "                    \n",
    "                    # Save locally\n",
    "                    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "                        f.write(f\"Transcription of: {audio_file}\\n\")\n",
    "                        f.write(f\"Model: {model}\\n\")\n",
    "                        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                        f.write(transcription)\n",
    "                    \n",
    "                    print(f\"\\n‚úÖ Transcription complete for: {audio_file}\")\n",
    "                    print(f\"üìÑ Saved as: {output_filename}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ùå Error transcribing {audio_file}: {str(e)}\")\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"üéâ TRANSCRIPTION COMPLETE!\")\n",
    "            print(f\"   Files processed: {len(transcription_results)}\")\n",
    "            print(\"\\nüëá Download your transcriptions in the next step\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "            if \"API key\" in str(e) or \"authentication\" in str(e).lower():\n",
    "                print(\"\\nüí° Please check that your API key is correct.\")\n",
    "\n",
    "transcribe_button = widgets.Button(\n",
    "    description='üöÄ Start Transcription',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='50px')\n",
    ")\n",
    "transcribe_button.on_click(run_transcription)\n",
    "\n",
    "display(transcribe_button)\n",
    "display(HTML(\"<br>\"))\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf70b03",
   "metadata": {},
   "source": [
    "## Step 6: Download Your Transcriptions üì•\n",
    "\n",
    "After transcription is complete, click below to download your files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_output = widgets.Output()\n",
    "\n",
    "def download_transcriptions(b):\n",
    "    with download_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if not transcription_results:\n",
    "            print(\"‚ùå No transcriptions available yet. Please run Step 5 first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"üì• Preparing downloads...\\n\")\n",
    "        \n",
    "        for filename in transcription_results.keys():\n",
    "            try:\n",
    "                print(f\"   Downloading: {filename}\")\n",
    "                files.download(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Could not download {filename}: {e}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Downloads initiated! Check your browser's download folder.\")\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description='üì• Download All Transcriptions',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "download_button.on_click(download_transcriptions)\n",
    "\n",
    "display(download_button)\n",
    "display(download_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661407b5",
   "metadata": {},
   "source": [
    "## Step 7 (Optional): View Transcription Results üëÅÔ∏è\n",
    "\n",
    "Preview your transcription directly in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121afaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_output = widgets.Output()\n",
    "\n",
    "def show_preview(b):\n",
    "    with preview_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if not transcription_results:\n",
    "            print(\"‚ùå No transcriptions available yet. Please run Step 5 first.\")\n",
    "            return\n",
    "        \n",
    "        for filename, content in transcription_results.items():\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"üìÑ {filename}\")\n",
    "            print(\"=\" * 60)\n",
    "            print(content[:5000])  # Show first 5000 characters\n",
    "            if len(content) > 5000:\n",
    "                print(f\"\\n... [Truncated - {len(content) - 5000} more characters]\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "preview_button = widgets.Button(\n",
    "    description='üëÅÔ∏è Preview Transcriptions',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='200px', height='35px')\n",
    ")\n",
    "preview_button.on_click(show_preview)\n",
    "\n",
    "display(preview_button)\n",
    "display(preview_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef26aef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ÑπÔ∏è Help & Troubleshooting\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "**\"API key not valid\"**\n",
    "- Make sure you copied the entire API key\n",
    "- Get a new key at: https://aistudio.google.com/app/apikey\n",
    "\n",
    "**\"File format not supported\"**\n",
    "- Supported formats: MP3, WAV, M4A, FLAC, OGG, WEBM, MP4, AAC\n",
    "- Try converting your file to MP3\n",
    "\n",
    "**\"Transcription takes too long\"**\n",
    "- Try using \"Gemini 2.5 Flash\" for faster processing\n",
    "- Enable audio splitting for long files\n",
    "\n",
    "**\"Output is not what I expected\"**\n",
    "- Try a different transcription style\n",
    "- Use the custom prompt option for specific needs\n",
    "\n",
    "---\n",
    "\n",
    "*Created by ZMO AI Pipelines*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
