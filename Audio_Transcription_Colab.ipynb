{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a95d729",
   "metadata": {},
   "source": [
    "## Step 1: Setup (Run this first!) ‚öôÔ∏è\n",
    "\n",
    "Click the ‚ñ∂Ô∏è button to install the required software. This may take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q google-genai pydub ipywidgets\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import mimetypes\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output, Markdown\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# ============================================\n",
    "# SUPPORTED FILE FORMATS\n",
    "# ============================================\n",
    "\n",
    "# Audio formats supported by Gemini\n",
    "SUPPORTED_AUDIO_FORMATS = {\n",
    "    '.mp3': 'audio/mpeg',\n",
    "    '.wav': 'audio/wav',\n",
    "    '.m4a': 'audio/mp4',\n",
    "    '.flac': 'audio/flac',\n",
    "    '.ogg': 'audio/ogg',\n",
    "    '.webm': 'audio/webm',\n",
    "    '.aac': 'audio/aac'\n",
    "}\n",
    "\n",
    "# Video formats supported by Gemini\n",
    "SUPPORTED_VIDEO_FORMATS = {\n",
    "    '.mp4': 'video/mp4',\n",
    "    '.mov': 'video/quicktime',\n",
    "    '.avi': 'video/x-msvideo',\n",
    "    '.mkv': 'video/x-matroska',\n",
    "    '.webm': 'video/webm'\n",
    "}\n",
    "\n",
    "# Combined formats\n",
    "ALL_SUPPORTED_FORMATS = {**SUPPORTED_AUDIO_FORMATS, **SUPPORTED_VIDEO_FORMATS}\n",
    "\n",
    "# ============================================\n",
    "# CREATE FOLDER STRUCTURE\n",
    "# ============================================\n",
    "\n",
    "# Define folder paths\n",
    "FOLDERS = {\n",
    "    'media': 'media_files',\n",
    "    'transcriptions': 'transcriptions',\n",
    "    'prompts': 'prompts',\n",
    "    'temp': 'temp_segments'\n",
    "}\n",
    "\n",
    "# Create all folders\n",
    "for folder_name, folder_path in FOLDERS.items():\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# CREATE PROMPT FILES\n",
    "# ============================================\n",
    "\n",
    "PROMPT_FILES = {\n",
    "    \"1_full_transcription.md\": {\n",
    "        \"title\": \"Full Audio Transcription\",\n",
    "        \"description\": \"Detailed word-for-word transcription with timestamps and speaker labels\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Full Audio Transcription\n",
    "\n",
    "## Role and Objective\n",
    "- Faithfully transcribe audio recordings into a publication-ready, accurate, and well-structured transcript.\n",
    "\n",
    "## Instructions\n",
    "- Transcribe exactly what is spoken without summarising or paraphrasing.\n",
    "- Use standard punctuation and sentence case; break into paragraphs at topic or speaker shifts.\n",
    "- Label each speaker consistently as Speaker 1:, Speaker 2:, etc.\n",
    "- Insert a timestamp at the start of every speaker turn in the format [hh:mm:ss].\n",
    "- For unclear audio, use [inaudible hh:mm:ss]. If unsure about a word or name, bracket with a question mark, e.g., [Kandahar?].\n",
    "- Mark non-speech events (e.g., [overlapping speech], [laughter], [applause], [music]) in square brackets.\n",
    "- Omit routine filler words (\"um\", \"uh\", repeated false starts) unless their inclusion changes the meaning of the sentence.\n",
    "- Normalize numbers and dates for clarity (e.g., \"twenty-five\" ‚Üí \"25\", \"first of May 2024\" ‚Üí \"1 May 2024\").\n",
    "- Preserve names and terms as heard; if unsure of spelling, use [term?].\n",
    "- Maintain any code-switching or language changes as spoken; do not translate.\n",
    "- Transcribe profanity, slurs, and sensitive language exactly as spoken.\n",
    "- After completing the transcription, validate the output to ensure it matches the defined formatting conventions and is free of omissions, correcting any errors identified before finalizing the output.\n",
    "\n",
    "## Output Format\n",
    "- Each speaker turn starts on a new line with a timestamp [hh:mm:ss], speaker label, and the transcript.\n",
    "- Clearly indicate non-speech and unclear audio using the conventions above.\n",
    "- Separate paragraphs (speaker turns or topic shifts) with a blank line.\n",
    "- Output should be in plain text or Markdown with appropriate spacing.\n",
    "\"\"\"\n",
    "    },\n",
    "    \"2_meeting_minutes.md\": {\n",
    "        \"title\": \"Meeting Minutes\",\n",
    "        \"description\": \"Summarized meeting notes with decisions, action items, and next steps\",\n",
    "        \"auto_split\": False,\n",
    "        \"content\": \"\"\"# Meeting Minutes\n",
    "\n",
    "## Role and Objective\n",
    "- Generate succinct, decision-oriented meeting minutes focused on actionable outcomes and relevant context.\n",
    "\n",
    "## Instructions\n",
    "- Summarize, do not transcribe. Capture only essential information for clarity and accountability.\n",
    "\n",
    "## Scope\n",
    "Include:\n",
    "- Header details (title, date/time, location, chair, note-taker, attendees, apologies)\n",
    "- Agenda coverage\n",
    "- Announcements\n",
    "- Decisions\n",
    "- Action items (specifying owner and due date)\n",
    "- Key risks/issues\n",
    "- Dependencies\n",
    "- Open questions\n",
    "- Next steps/next meeting\n",
    "\n",
    "Maintain only the context necessary to understand each decision, with brief rationale. Omit small talk and verbatim digressions.\n",
    "\n",
    "## Participants & Timing\n",
    "- List all attendees, apologies, chair, and note-taker.\n",
    "- Add a `[hh:mm:ss]` timestamp at the start of any decision, action, or announcement if available in the input.\n",
    "\n",
    "## Editing Rules\n",
    "- Capture the core point, not all rhetoric; avoid unintended paraphrasing or misrepresentation.\n",
    "- Normalize numbers and dates (e.g., 15 September 2025, 14:00‚Äì15:00 CEST).\n",
    "- Use consistent speaker names/roles. If unknown, default to \"Participant 1\", \"Participant 2\", etc.\n",
    "- For unclear audio, insert `[inaudible hh:mm:ss]`; for overlapping speakers, insert `[crosstalk]`.\n",
    "- If any action item is missing an owner or deadline, set as Owner: TBD / Due: TBD and flag this instance.\n",
    "\"\"\"\n",
    "    },\n",
    "    \"3_interview.md\": {\n",
    "        \"title\": \"Interview Transcription\",\n",
    "        \"description\": \"Q&A format with interviewer/interviewee labels and emotional context\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Interview Transcription\n",
    "\n",
    "## Role and Objective\n",
    "Please transcribe this interview accurately and professionally.\n",
    "\n",
    "## Instructions\n",
    "- Clearly distinguish between interviewer and interviewee\n",
    "- Format in a question-and-answer structure when possible\n",
    "- Include emotional context (laughter, pauses) in [brackets]\n",
    "- Maintain the conversational flow and natural speech patterns\n",
    "- Preserve the tone and style of both speakers\n",
    "- Note any significant pauses or interruptions\n",
    "- Keep the chronological order of the conversation\n",
    "- Use timestamps [hh:mm:ss] at speaker changes\n",
    "\"\"\"\n",
    "    },\n",
    "    \"4_lecture.md\": {\n",
    "        \"title\": \"Lecture/Educational Content\",\n",
    "        \"description\": \"Structured notes with key concepts, definitions, and Q&A sections\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Lecture Transcription\n",
    "\n",
    "## Role and Objective\n",
    "Transcribe the educational content accurately, focusing strictly on the key concepts and main points.\n",
    "\n",
    "## Instructions\n",
    "- Structure the transcript in clear paragraphs\n",
    "- Only include slide references or visual descriptions when explicitly mentioned in the material\n",
    "- Note audience questions and responses in a separate section\n",
    "- Preserve all academic terminology and technical language precisely; do not simplify unless specifically requested\n",
    "- Organize the material logically for educational clarity\n",
    "- Highlight major concepts and definitions\n",
    "\n",
    "## Focus Areas\n",
    "Extract only the central ideas and supporting points emphasized by the speaker:\n",
    "- Thesis and key claims\n",
    "- Evidence and examples\n",
    "- Methodologies\n",
    "- Conclusions\n",
    "- Implications or limitations\n",
    "\n",
    "## Output Format\n",
    "```\n",
    "# Summary (‚â§ 200 words)\n",
    "\n",
    "## Core Takeaways (5-8 bullets)\n",
    "\n",
    "## Key Points by Section\n",
    "\n",
    "## Definitions & Concepts\n",
    "\n",
    "## Evidence & Examples\n",
    "\n",
    "## Q&A (if any)\n",
    "\n",
    "## Keywords/Tags\n",
    "```\n",
    "\"\"\"\n",
    "    },\n",
    "    \"5_qa_summary.md\": {\n",
    "        \"title\": \"Q&A Summary\",\n",
    "        \"description\": \"Extract and condense only questions and answers from recordings\",\n",
    "        \"auto_split\": False,\n",
    "        \"content\": \"\"\"# Q&A-Focused Transcription (Extract & Condense)\n",
    "\n",
    "## Role and Objective\n",
    "Produce a concise Q&A transcript from audio recordings by extracting and condensing only the essential questions and answers.\n",
    "\n",
    "## Instructions\n",
    "- Include only questions and answers in the transcript\n",
    "- Omit introductions, bios, housekeeping comments, and small talk\n",
    "- For each question, summarize to the essential inquiry in 1‚Äì2 sentences, retaining key names, citations, numbers, and dates\n",
    "- For each answer, distill the main claim(s) and provide up to 3‚Äì4 supporting points or examples\n",
    "\n",
    "## Speakers & Timestamps\n",
    "- Label each turn as: `[hh:mm:ss] Q (Name/Audience #):` and `[hh:mm:ss] A (Name/Role):`\n",
    "- If the speaker is unnamed, use Audience 1, Audience 2, etc.\n",
    "\n",
    "## Output Format\n",
    "- Output must be strictly in Markdown\n",
    "- Each Q and A block appears on its own line\n",
    "- Insert a single blank line between each Q/A pair\n",
    "\"\"\"\n",
    "    },\n",
    "    \"6_translation.md\": {\n",
    "        \"title\": \"Full Audio Translation (to English)\",\n",
    "        \"description\": \"Translate non-English audio to English with cultural context notes\",\n",
    "        \"auto_split\": True,\n",
    "        \"content\": \"\"\"# Full Audio Translation (to English)\n",
    "\n",
    "## Role and Objective\n",
    "- Faithfully transcribe and translate audio recordings into a publication-ready, accurate, and well-structured English transcript.\n",
    "\n",
    "## Instructions\n",
    "- Translate all spoken content into English, regardless of the original language(s)\n",
    "- Maintain the original meaning and tone as closely as possible while producing natural, fluent English\n",
    "- Use standard punctuation and sentence case; break into paragraphs at topic or speaker shifts\n",
    "- Label each speaker consistently as Speaker 1:, Speaker 2:, etc.\n",
    "- Insert a timestamp at the start of every speaker turn in the format [hh:mm:ss]\n",
    "- For unclear audio, use [inaudible hh:mm:ss]. If unsure about a word or name, bracket with a question mark, e.g., [Kandahar?]\n",
    "- Mark non-speech events (e.g., [overlapping speech], [laughter], [applause], [music]) in square brackets\n",
    "\n",
    "## Language Handling\n",
    "- When the original language changes (code-switching), indicate the original language in brackets, e.g., [in French:] before the translated text if relevant for context\n",
    "- For culturally specific terms, idiomatic expressions, or words with no direct English equivalent, provide the English translation followed by the original term in parentheses, e.g., \"religious endowment (waqf)\", \"neighborhood (mahalla)\"\n",
    "\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write prompt files to disk\n",
    "for filename, prompt_data in PROMPT_FILES.items():\n",
    "    filepath = os.path.join(FOLDERS['prompts'], filename)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(prompt_data['content'])\n",
    "\n",
    "# ============================================\n",
    "# LOAD PROMPTS FROM FILES\n",
    "# ============================================\n",
    "\n",
    "def load_prompts():\n",
    "    \"\"\"Load all prompts from the prompts folder.\"\"\"\n",
    "    prompts = {}\n",
    "    prompts_dir = Path(FOLDERS['prompts'])\n",
    "    \n",
    "    for filepath in sorted(prompts_dir.glob('*.md')):\n",
    "        filename = filepath.name\n",
    "        if filename in PROMPT_FILES:\n",
    "            meta = PROMPT_FILES[filename]\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            prompts[meta['title']] = {\n",
    "                'description': meta['description'],\n",
    "                'auto_split': meta['auto_split'],\n",
    "                'content': content,\n",
    "                'filepath': str(filepath)\n",
    "            }\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "PROMPTS = load_prompts()\n",
    "\n",
    "# Print folder structure\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print()\n",
    "print(\"üìÅ Folder structure created:\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ üìÇ media_files/      ‚Üê Upload your audio/video here\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ üìÇ transcriptions/   ‚Üê Output files saved here\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ üìÇ prompts/          ‚Üê Editable prompt templates\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ 1_full_transcription.md\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ 2_meeting_minutes.md\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ 3_interview.md\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ 4_lecture.md\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ 5_qa_summary.md\")\n",
    "print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ 6_translation.md\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ üìÇ temp_segments/    ‚Üê Temporary audio segments\")\n",
    "print()\n",
    "print(\"üéµ Supported audio formats:\", \", \".join(sorted(SUPPORTED_AUDIO_FORMATS.keys())))\n",
    "print(\"üé¨ Supported video formats:\", \", \".join(sorted(SUPPORTED_VIDEO_FORMATS.keys())))\n",
    "print()\n",
    "print(\"üí° Tip: You can edit the prompt files in the 'prompts' folder to customize them!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a52a50",
   "metadata": {},
   "source": [
    "## Step 2: Enter Your API Key üîë\n",
    "\n",
    "Enter your Google Gemini API key below. \n",
    "\n",
    "**Don't have one?** Get it free at: https://aistudio.google.com/app/api-keys\n",
    "\n",
    "Your API key is entered securely (hidden like a password)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4debbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a secure password field for the API key\n",
    "api_key_input = widgets.Password(\n",
    "    placeholder='Paste your API key here',\n",
    "    description='API Key:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '80px'}\n",
    ")\n",
    "\n",
    "api_key_status = widgets.HTML(value=\"\")\n",
    "\n",
    "def validate_api_key(change):\n",
    "    if len(change['new']) > 20:\n",
    "        api_key_status.value = \"<span style='color: green;'>‚úÖ API key entered</span>\"\n",
    "    else:\n",
    "        api_key_status.value = \"<span style='color: orange;'>‚è≥ Please enter your full API key</span>\"\n",
    "\n",
    "api_key_input.observe(validate_api_key, names='value')\n",
    "\n",
    "# Check for Colab Secret\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    secret_key = userdata.get('GEMINI_API_KEY')\n",
    "    if secret_key:\n",
    "        api_key_input.value = secret_key\n",
    "        api_key_status.value = \"<span style='color: green;'>‚úÖ API key loaded from Colab Secrets</span>\"\n",
    "except Exception:\n",
    "    pass # Secret not found or error accessing it\n",
    "\n",
    "display(HTML(\"<b>Enter your Gemini API key:</b>\"))\n",
    "display(api_key_input)\n",
    "display(api_key_status)\n",
    "display(HTML(\"<br><i>üí° Tip: Your key starts with 'AIza...'</i>\"))\n",
    "display(HTML(\"<i>(Or add 'GEMINI_API_KEY' to your Colab Secrets for auto-loading)</i>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc9d26",
   "metadata": {},
   "source": [
    "## Step 3: Upload Your Media File(s) üìÅ\n",
    "\n",
    "Click the button below to select and upload your audio or video file(s).\n",
    "\n",
    "**Supported audio formats:** MP3, WAV, M4A, FLAC, OGG, WEBM, AAC\n",
    "\n",
    "**Supported video formats:** MP4, MOV, AVI, MKV, WEBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store uploaded files\n",
    "uploaded_files = []\n",
    "\n",
    "upload_status = widgets.HTML(value=\"\")\n",
    "\n",
    "def upload_media_files(b):\n",
    "    global uploaded_files\n",
    "    upload_status.value = \"<span style='color: blue;'>üì§ Upload dialog opened... Select your file(s)</span>\"\n",
    "    \n",
    "    try:\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if uploaded:\n",
    "            uploaded_files = []\n",
    "            valid_files = []\n",
    "            invalid_files = []\n",
    "            \n",
    "            for filename, content in uploaded.items():\n",
    "                ext = Path(filename).suffix.lower()\n",
    "                if ext in ALL_SUPPORTED_FORMATS:\n",
    "                    # Save file to media folder\n",
    "                    filepath = os.path.join(FOLDERS['media'], filename)\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        f.write(content)\n",
    "                    uploaded_files.append(filepath)\n",
    "                    valid_files.append((filename, ext))\n",
    "                else:\n",
    "                    invalid_files.append(filename)\n",
    "            \n",
    "            status_html = \"\"\n",
    "            if valid_files:\n",
    "                status_html += f\"<span style='color: green;'>‚úÖ Uploaded {len(valid_files)} file(s) to <code>media_files/</code>:</span><br>\"\n",
    "                for f, ext in valid_files:\n",
    "                    icon = \"üé¨\" if ext in SUPPORTED_VIDEO_FORMATS else \"üéµ\"\n",
    "                    status_html += f\"&nbsp;&nbsp;&nbsp;{icon} {f}<br>\"\n",
    "            if invalid_files:\n",
    "                status_html += f\"<span style='color: red;'>‚ùå Skipped {len(invalid_files)} unsupported file(s):</span><br>\"\n",
    "                for f in invalid_files:\n",
    "                    status_html += f\"&nbsp;&nbsp;&nbsp;‚ö†Ô∏è {f}<br>\"\n",
    "                status_html += f\"<br><i>Supported: {', '.join(sorted(ALL_SUPPORTED_FORMATS.keys()))}</i>\"\n",
    "            \n",
    "            upload_status.value = status_html\n",
    "        else:\n",
    "            upload_status.value = \"<span style='color: orange;'>‚ö†Ô∏è No files uploaded</span>\"\n",
    "    except Exception as e:\n",
    "        upload_status.value = f\"<span style='color: red;'>‚ùå Error: {str(e)}</span>\"\n",
    "\n",
    "upload_button = widgets.Button(\n",
    "    description='üìÅ Upload Audio/Video Files',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "upload_button.on_click(upload_media_files)\n",
    "\n",
    "display(upload_button)\n",
    "display(upload_status)\n",
    "display(HTML(\"<br><i>üí° Files will be saved to the <code>media_files/</code> folder</i>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43dd50b",
   "metadata": {},
   "source": [
    "## Step 4: Choose Your Settings üéõÔ∏è\n",
    "\n",
    "Select the transcription style and options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aff251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SETTINGS WIDGETS\n",
    "# ============================================\n",
    "\n",
    "# Model selection (Gemini 3 Pro uses thinking_level, Flash uses budget)\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Gemini 3 Pro (Highest quality)', 'gemini-3-pro-preview'),\n",
    "        ('Gemini 3 Flash (Faster, good quality)', 'gemini-3-flash-preview'),\n",
    "    ],\n",
    "    value='gemini-3-pro-preview',\n",
    "    description='AI Model:',\n",
    "    style={'description_width': '100px'},\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "# Model info display\n",
    "model_info = widgets.HTML(value=\"\")\n",
    "\n",
    "def update_model_info(change):\n",
    "    model = change['new']\n",
    "    if \"3-pro\" in model:\n",
    "        model_info.value = \"\"\"\n",
    "        <div style='background: #e8f5e9; padding: 10px; border-radius: 5px; margin: 5px 0;'>\n",
    "        üß† <b>Gemini 3 Pro</b>: Thinking level LOW, Temperature 0.1<br>\n",
    "        üéµ Best for: Complex audio, multiple speakers, challenging accents\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        model_info.value = \"\"\"\n",
    "        <div style='background: #e3f2fd; padding: 10px; border-radius: 5px; margin: 5px 0;'>\n",
    "        ‚ö° <b>Gemini 3 Flash</b>: Thinking level MINIMAL, Temperature 0.2<br>\n",
    "        üéµ Best for: Standard recordings, faster processing\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "model_dropdown.observe(update_model_info, names='value')\n",
    "update_model_info({'new': model_dropdown.value})\n",
    "\n",
    "# Reload prompts button (in case user edited them)\n",
    "def reload_prompts_click(b):\n",
    "    global PROMPTS\n",
    "    PROMPTS = load_prompts()\n",
    "    prompt_dropdown.options = list(PROMPTS.keys())\n",
    "    prompt_status.value = \"<span style='color: green;'>‚úÖ Prompts reloaded from files!</span>\"\n",
    "\n",
    "reload_button = widgets.Button(\n",
    "    description='üîÑ Reload Prompts',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "reload_button.on_click(reload_prompts_click)\n",
    "\n",
    "prompt_status = widgets.HTML(value=\"\")\n",
    "\n",
    "# Prompt selection\n",
    "prompt_dropdown = widgets.Dropdown(\n",
    "    options=list(PROMPTS.keys()),\n",
    "    value=list(PROMPTS.keys())[0] if PROMPTS else None,\n",
    "    description='Style:',\n",
    "    style={'description_width': '100px'},\n",
    "    layout=widgets.Layout(width='350px')\n",
    ")\n",
    "\n",
    "# Prompt description display\n",
    "prompt_description = widgets.HTML(\n",
    "    value=f\"<i>üìù {PROMPTS[list(PROMPTS.keys())[0]]['description']}</i>\" if PROMPTS else \"\"\n",
    ")\n",
    "\n",
    "# Prompt file path display\n",
    "prompt_filepath = widgets.HTML(\n",
    "    value=f\"<code style='font-size: 11px;'>üìÑ {PROMPTS[list(PROMPTS.keys())[0]]['filepath']}</code>\" if PROMPTS else \"\"\n",
    ")\n",
    "\n",
    "# Preview prompt button and output\n",
    "preview_output = widgets.Output(layout=widgets.Layout(max_height='300px', overflow='auto'))\n",
    "\n",
    "def preview_prompt_click(b):\n",
    "    with preview_output:\n",
    "        clear_output()\n",
    "        if prompt_dropdown.value and prompt_dropdown.value in PROMPTS:\n",
    "            selected = prompt_dropdown.value\n",
    "            filepath = PROMPTS[selected]['filepath']\n",
    "            print(f\"üìÑ Prompt file: {filepath}\\n\")\n",
    "            print(\"=\" * 50)\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                print(f.read())\n",
    "\n",
    "preview_button = widgets.Button(\n",
    "    description='üëÅÔ∏è Preview Prompt',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "preview_button.on_click(preview_prompt_click)\n",
    "\n",
    "def update_prompt_description(change):\n",
    "    selected = change['new']\n",
    "    if selected in PROMPTS:\n",
    "        desc = PROMPTS[selected]['description']\n",
    "        filepath = PROMPTS[selected]['filepath']\n",
    "        auto_split = PROMPTS[selected]['auto_split']\n",
    "        prompt_description.value = f\"<i>üìù {desc}</i>\"\n",
    "        prompt_filepath.value = f\"<code style='font-size: 11px;'>üìÑ {filepath}</code>\"\n",
    "        # Update split checkbox based on prompt recommendation\n",
    "        split_checkbox.value = auto_split\n",
    "        # Clear preview when changing selection\n",
    "        with preview_output:\n",
    "            clear_output()\n",
    "\n",
    "prompt_dropdown.observe(update_prompt_description, names='value')\n",
    "\n",
    "# Audio splitting options\n",
    "split_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Split long files into segments (recommended for files > 10 min)',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "segment_slider = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=5,\n",
    "    max=30,\n",
    "    step=5,\n",
    "    description='Segment length (minutes):',\n",
    "    style={'description_width': '180px'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Custom prompt option\n",
    "use_custom_prompt = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Use custom prompt instead',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "custom_prompt_text = widgets.Textarea(\n",
    "    placeholder='Enter your custom transcription instructions here...\\n\\nExample: Please transcribe this audio in French, focusing on technical terminology.',\n",
    "    layout=widgets.Layout(width='500px', height='150px'),\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "def toggle_custom_prompt(change):\n",
    "    custom_prompt_text.disabled = not change['new']\n",
    "    prompt_dropdown.disabled = change['new']\n",
    "    preview_button.disabled = change['new']\n",
    "    reload_button.disabled = change['new']\n",
    "\n",
    "use_custom_prompt.observe(toggle_custom_prompt, names='value')\n",
    "\n",
    "# Display all settings\n",
    "display(HTML(\"<h3>ü§ñ Select AI Model</h3>\"))\n",
    "display(model_dropdown)\n",
    "display(model_info)\n",
    "\n",
    "display(HTML(\"<h3>üìã Select Transcription Style</h3>\"))\n",
    "display(HTML(\"<p><i>üí° You can edit the prompt files in the <code>prompts/</code> folder and click 'Reload Prompts'</i></p>\"))\n",
    "display(widgets.HBox([prompt_dropdown, reload_button]))\n",
    "display(prompt_status)\n",
    "display(prompt_description)\n",
    "display(prompt_filepath)\n",
    "display(widgets.HBox([preview_button]))\n",
    "display(preview_output)\n",
    "\n",
    "display(HTML(\"<br>\"))\n",
    "display(use_custom_prompt)\n",
    "display(custom_prompt_text)\n",
    "\n",
    "display(HTML(\"<h3>‚úÇÔ∏è File Splitting Options</h3>\"))\n",
    "display(split_checkbox)\n",
    "display(segment_slider)\n",
    "display(HTML(\"<i>üí° Splitting helps with long recordings and improves accuracy.</i>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d5b7c",
   "metadata": {},
   "source": [
    "## Step 5: Start Transcription! üöÄ\n",
    "\n",
    "Click the button below to start transcribing your audio file(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TRANSCRIPTION ENGINE\n",
    "# ============================================\n",
    "\n",
    "class ColabMediaTranscriber:\n",
    "    \"\"\"\n",
    "    Audio/Video Transcriber for Google Colab using Gemini API.\n",
    "    Supports audio files (with optional splitting) and video files.\n",
    "    Uses system_instruction for prompts with optimized thinking settings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key, model='gemini-3-pro-preview', prompt_file=None, custom_prompt=None):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.client = genai.Client(api_key=self.api_key)\n",
    "        self.prompt_file = prompt_file\n",
    "        self.custom_prompt = custom_prompt\n",
    "        self.generation_config = self._setup_generation_config()\n",
    "    \n",
    "    def _get_system_instruction(self):\n",
    "        \"\"\"Load system instruction from prompt file or custom prompt.\"\"\"\n",
    "        if self.custom_prompt:\n",
    "            return self.custom_prompt\n",
    "        \n",
    "        if self.prompt_file:\n",
    "            try:\n",
    "                with open(self.prompt_file, 'r', encoding='utf-8') as f:\n",
    "                    return f.read()\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error reading prompt file: {e}\")\n",
    "                raise\n",
    "        \n",
    "        # Default fallback\n",
    "        return \"Transcribe this audio/video accurately. Extract all spoken content.\"\n",
    "    \n",
    "    def _setup_generation_config(self):\n",
    "        \"\"\"Configure generation settings based on model type.\n",
    "        \n",
    "        Gemini 3 Pro: Uses thinking_level ('low'), temperature 0.1\n",
    "        Gemini 3 Flash: Uses thinking_level ('MINIMAL'), temperature 0.2\n",
    "        \"\"\"\n",
    "        config_params = {\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 40,\n",
    "            \"max_output_tokens\": 65535,\n",
    "            \"response_mime_type\": \"text/plain\",\n",
    "            \"system_instruction\": self._get_system_instruction(),\n",
    "        }\n",
    "        \n",
    "        if \"3-pro\" in self.model.lower():\n",
    "            # Gemini 3 Pro: Use thinking_level (not budget), low temperature\n",
    "            config_params[\"temperature\"] = 0.1\n",
    "            config_params[\"thinking_config\"] = types.ThinkingConfig(thinking_level=\"low\")\n",
    "        else:\n",
    "            # Gemini 3 Flash: Use thinking_level MINIMAL, slightly higher temperature\n",
    "            config_params[\"temperature\"] = 0.2\n",
    "            config_params[\"thinking_config\"] = types.ThinkingConfig(thinking_level=\"minimal\")\n",
    "        \n",
    "        # Safety settings for archival content\n",
    "        config_params[\"safety_settings\"] = [\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            ),\n",
    "            types.SafetySetting(\n",
    "                category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return types.GenerateContentConfig(**config_params)\n",
    "    \n",
    "    def is_video_file(self, file_path):\n",
    "        \"\"\"Check if file is a video file.\"\"\"\n",
    "        ext = Path(file_path).suffix.lower()\n",
    "        return ext in SUPPORTED_VIDEO_FORMATS\n",
    "    \n",
    "    def get_mime_type(self, file_path):\n",
    "        \"\"\"Get MIME type for a file.\"\"\"\n",
    "        ext = Path(file_path).suffix.lower()\n",
    "        return ALL_SUPPORTED_FORMATS.get(ext, 'audio/mpeg')\n",
    "    \n",
    "    def split_audio(self, audio_file_path, segment_minutes=10):\n",
    "        \"\"\"Split audio into segments and save to temp folder.\"\"\"\n",
    "        try:\n",
    "            segment_ms = segment_minutes * 60 * 1000\n",
    "            audio = AudioSegment.from_file(audio_file_path)\n",
    "            \n",
    "            if len(audio) <= segment_ms:\n",
    "                return [audio_file_path]\n",
    "            \n",
    "            segments = []\n",
    "            base_name = Path(audio_file_path).stem\n",
    "            ext = Path(audio_file_path).suffix\n",
    "            \n",
    "            for i, start in enumerate(range(0, len(audio), segment_ms), start=1):\n",
    "                end = min(start + segment_ms, len(audio))\n",
    "                chunk = audio[start:end]\n",
    "                # Save segments to temp folder\n",
    "                segment_path = os.path.join(FOLDERS['temp'], f\"{base_name}_segment_{i:02d}{ext}\")\n",
    "                \n",
    "                # Map extensions to export formats\n",
    "                format_map = {'m4a': 'mp4', 'mp4': 'mp4', 'mp3': 'mp3', \n",
    "                              'wav': 'wav', 'flac': 'flac', 'ogg': 'ogg'}\n",
    "                export_format = format_map.get(ext.lstrip('.').lower(), 'mp3')\n",
    "                chunk.export(segment_path, format=export_format)\n",
    "                segments.append(segment_path)\n",
    "            \n",
    "            return segments\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not split audio: {e}. Processing as single file.\")\n",
    "            return [audio_file_path]\n",
    "\n",
    "    def split_video(self, video_file_path, segment_minutes=10):\n",
    "        \"\"\"Split video into segments using ffmpeg.\"\"\"\n",
    "        try:\n",
    "            import subprocess\n",
    "            import math\n",
    "            \n",
    "            # Check if ffmpeg is available\n",
    "            try:\n",
    "                subprocess.run([\"ffmpeg\", \"-version\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
    "            except FileNotFoundError:\n",
    "                print(\"‚ö†Ô∏è ffmpeg not found. Cannot split video. Processing as single file.\")\n",
    "                return [video_file_path]\n",
    "\n",
    "            # Get video duration using ffprobe\n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", video_file_path],\n",
    "                    stdout=subprocess.PIPE,\n",
    "                    stderr=subprocess.STDOUT,\n",
    "                    check=True\n",
    "                )\n",
    "                duration = float(result.stdout)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Could not determine video duration: {e}. Processing as single file.\")\n",
    "                return [video_file_path]\n",
    "            \n",
    "            segment_seconds = segment_minutes * 60\n",
    "            if duration <= segment_seconds:\n",
    "                return [video_file_path]\n",
    "            \n",
    "            segments = []\n",
    "            base_name = Path(video_file_path).stem\n",
    "            ext = Path(video_file_path).suffix\n",
    "            \n",
    "            num_segments = math.ceil(duration / segment_seconds)\n",
    "            \n",
    "            print(f\"   ‚úÇÔ∏è Splitting video into {num_segments} segments...\")\n",
    "            \n",
    "            for i in range(num_segments):\n",
    "                start_time = i * segment_seconds\n",
    "                segment_path = os.path.join(FOLDERS['temp'], f\"{base_name}_segment_{i+1:02d}{ext}\")\n",
    "                \n",
    "                # Use ffmpeg to split (stream copy for speed)\n",
    "                # -ss before -i is faster but less accurate keyframes. \n",
    "                # -avoid_negative_ts 1 shifts timestamps to be positive.\n",
    "                cmd = [\n",
    "                    \"ffmpeg\", \"-y\",\n",
    "                    \"-ss\", str(start_time),\n",
    "                    \"-t\", str(segment_seconds),\n",
    "                    \"-i\", video_file_path,\n",
    "                    \"-c\", \"copy\",\n",
    "                    \"-avoid_negative_ts\", \"1\",\n",
    "                    \"-loglevel\", \"error\",\n",
    "                    segment_path\n",
    "                ]\n",
    "                subprocess.run(cmd, check=True)\n",
    "                segments.append(segment_path)\n",
    "                \n",
    "            return segments\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not split video: {e}. Processing as single file.\")\n",
    "            return [video_file_path]\n",
    "    \n",
    "    def transcribe_with_bytes(self, file_path):\n",
    "        \"\"\"Transcribe a media file by sending bytes directly (for smaller files).\"\"\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            media_bytes = f.read()\n",
    "        \n",
    "        mime_type = self.get_mime_type(file_path)\n",
    "        \n",
    "        media_part = types.Part.from_bytes(\n",
    "            data=media_bytes,\n",
    "            mime_type=mime_type\n",
    "        )\n",
    "        \n",
    "        # Simple user prompt - system instruction is in config\n",
    "        user_prompt = \"Please perform complete transcription.\"\n",
    "        \n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=[media_part, user_prompt],\n",
    "            config=self.generation_config\n",
    "        )\n",
    "        \n",
    "        return response.text.strip()\n",
    "    \n",
    "    def transcribe_with_upload(self, file_path):\n",
    "        \"\"\"Transcribe a media file by uploading first (for larger files like videos).\"\"\"\n",
    "        print(f\"   ‚îî‚îÄ üì§ Uploading file to Gemini...\")\n",
    "        \n",
    "        # Upload the file\n",
    "        uploaded_file = self.client.files.upload(\n",
    "            file=file_path,\n",
    "            config=types.UploadFileConfig(\n",
    "                display_name=Path(file_path).name,\n",
    "                mime_type=self.get_mime_type(file_path)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Wait for processing if needed\n",
    "        while uploaded_file.state == 'PROCESSING':\n",
    "            print(f\"   ‚îî‚îÄ ‚è≥ Processing upload...\")\n",
    "            time.sleep(2)\n",
    "            uploaded_file = self.client.files.get(name=uploaded_file.name)\n",
    "        \n",
    "        if uploaded_file.state == 'FAILED':\n",
    "            raise Exception(f\"File upload failed: {uploaded_file.error}\")\n",
    "        \n",
    "        print(f\"   ‚îî‚îÄ ‚úÖ Upload complete, transcribing...\")\n",
    "        \n",
    "        # Simple user prompt - system instruction is in config\n",
    "        user_prompt = \"Please perform complete transcription.\"\n",
    "        \n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=[uploaded_file, user_prompt],\n",
    "            config=self.generation_config\n",
    "        )\n",
    "        \n",
    "        # Clean up uploaded file\n",
    "        try:\n",
    "            self.client.files.delete(name=uploaded_file.name)\n",
    "        except Exception:\n",
    "            pass  # Ignore cleanup errors\n",
    "        \n",
    "        return response.text.strip()\n",
    "    \n",
    "    def transcribe(self, file_path, use_upload=False):\n",
    "        \"\"\"Transcribe a single media file.\"\"\"\n",
    "        if use_upload or self.is_video_file(file_path):\n",
    "            return self.transcribe_with_upload(file_path)\n",
    "        else:\n",
    "            return self.transcribe_with_bytes(file_path)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# TRANSCRIPTION BUTTON AND OUTPUT\n",
    "# ============================================\n",
    "\n",
    "output_area = widgets.Output()\n",
    "transcription_results = {}  # Store results for download\n",
    "\n",
    "def run_transcription(b):\n",
    "    global transcription_results\n",
    "    transcription_results = {}\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        # Get API key\n",
    "        api_key = api_key_input.value\n",
    "        \n",
    "        # If widget is empty, try to load from secrets dynamically\n",
    "        if not api_key:\n",
    "            try:\n",
    "                from google.colab import userdata\n",
    "                api_key = userdata.get('GEMINI_API_KEY')\n",
    "                if api_key:\n",
    "                    print(\"üîë Found API key in Colab Secrets\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        # Validate inputs\n",
    "        if not api_key or len(api_key) < 20:\n",
    "            print(\"‚ùå Please enter a valid API key in Step 2\")\n",
    "            print(\"   (Or add 'GEMINI_API_KEY' to Colab Secrets and re-run Step 2)\")\n",
    "            return\n",
    "        \n",
    "        if not uploaded_files:\n",
    "            print(\"‚ùå Please upload at least one media file in Step 3\")\n",
    "            return\n",
    "        \n",
    "        # Get settings\n",
    "        model = model_dropdown.value\n",
    "        split_enabled = split_checkbox.value\n",
    "        segment_minutes = segment_slider.value\n",
    "        \n",
    "        # Get prompt\n",
    "        custom_prompt = None\n",
    "        prompt_file = None\n",
    "        selected_prompt_name = \"Custom\"\n",
    "        \n",
    "        if use_custom_prompt.value and custom_prompt_text.value.strip():\n",
    "            custom_prompt = custom_prompt_text.value.strip()\n",
    "            print(\"üìù Using custom prompt\")\n",
    "        else:\n",
    "            selected_prompt_name = prompt_dropdown.value\n",
    "            # Reload prompt from file to get latest version\n",
    "            prompt_file = PROMPTS[selected_prompt_name]['filepath']\n",
    "            print(f\"üìù Using: {selected_prompt_name}\")\n",
    "            print(f\"   üìÑ From: {prompt_file}\")\n",
    "        \n",
    "        print(f\"ü§ñ Model: {model}\")\n",
    "        if \"3-pro\" in model:\n",
    "            print(\"üß† Thinking: level=LOW | Temperature: 0.1\")\n",
    "        else:\n",
    "            print(\"‚ö° Thinking: dynamic | Temperature: 0.2\")\n",
    "        print(f\"‚úÇÔ∏è File splitting: {'Enabled' if split_enabled else 'Disabled'}\")\n",
    "        if split_enabled:\n",
    "            print(f\"   Segment length: {segment_minutes} minutes\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            # Initialize transcriber\n",
    "            transcriber = ColabMediaTranscriber(api_key, model, prompt_file, custom_prompt)\n",
    "            print(\"‚úÖ Connected to Gemini API\\n\")\n",
    "            \n",
    "            # Process each file\n",
    "            for i, media_file in enumerate(uploaded_files, 1):\n",
    "                filename = Path(media_file).name\n",
    "                is_video = transcriber.is_video_file(media_file)\n",
    "                file_type = \"video\" if is_video else \"audio\"\n",
    "                file_icon = \"üé¨\" if is_video else \"üéµ\"\n",
    "                \n",
    "                print(f\"\\n{file_icon} Processing {file_type} {i}/{len(uploaded_files)}: {filename}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                try:\n",
    "                    segments = []\n",
    "                    if split_enabled:\n",
    "                        if is_video:\n",
    "                            segments = transcriber.split_video(media_file, segment_minutes)\n",
    "                        else:\n",
    "                            segments = transcriber.split_audio(media_file, segment_minutes)\n",
    "                    else:\n",
    "                        segments = [media_file]\n",
    "\n",
    "                    if len(segments) > 1:\n",
    "                        print(f\"   ‚úÇÔ∏è Split into {len(segments)} segments (saved to temp_segments/)\")\n",
    "                    \n",
    "                    transcription_parts = []\n",
    "                    for j, segment in enumerate(segments, 1):\n",
    "                        if len(segments) > 1:\n",
    "                            print(f\"   ‚è≥ Transcribing segment {j}/{len(segments)}...\")\n",
    "                        else:\n",
    "                            print(\"   ‚è≥ Transcribing...\")\n",
    "                            \n",
    "                        # Use upload for videos or large segments, bytes for small audio\n",
    "                        # But transcribe() handles this logic automatically based on file type\n",
    "                        # However, split audio segments are usually small enough for bytes, \n",
    "                        # but split video segments might still be large.\n",
    "                        # The transcribe method checks is_video_file.\n",
    "                        \n",
    "                        result = transcriber.transcribe(segment)\n",
    "                        \n",
    "                        if len(segments) > 1:\n",
    "                            transcription_parts.append(f\"[Segment {j}]\\n{result}\")\n",
    "                            print(f\"   ‚úÖ Segment {j} complete\")\n",
    "                        else:\n",
    "                            transcription_parts.append(result)\n",
    "                            print(\"   ‚úÖ Transcription complete\")\n",
    "                    \n",
    "                    transcription = \"\\n\\n\".join(transcription_parts)\n",
    "                    \n",
    "                    # Store result - save to transcriptions folder\n",
    "                    output_filename = Path(media_file).stem + \"_transcription.txt\"\n",
    "                    output_path = os.path.join(FOLDERS['transcriptions'], output_filename)\n",
    "                    transcription_results[output_filename] = {\n",
    "                        'content': transcription,\n",
    "                        'path': output_path\n",
    "                    }\n",
    "                    \n",
    "                    # Save to transcriptions folder\n",
    "                    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(f\"Transcription of: {filename}\\n\")\n",
    "                        f.write(f\"Model: {model}\\n\")\n",
    "                        f.write(f\"Prompt: {selected_prompt_name}\\n\")\n",
    "                        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                        f.write(transcription)\n",
    "                    \n",
    "                    print(f\"\\n‚úÖ Saved to: {output_path}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ùå Error transcribing {filename}: {str(e)}\")\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"üéâ TRANSCRIPTION COMPLETE!\")\n",
    "            print(f\"   Files processed: {len(transcription_results)}\")\n",
    "            print(f\"   üìÅ Output folder: {FOLDERS['transcriptions']}/\")\n",
    "            print(\"\\nüëá Download your transcriptions in the next step\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "            if \"API key\" in str(e) or \"authentication\" in str(e).lower():\n",
    "                print(\"\\nüí° Please check that your API key is correct.\")\n",
    "\n",
    "transcribe_button = widgets.Button(\n",
    "    description='üöÄ Start Transcription',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='50px')\n",
    ")\n",
    "transcribe_button.on_click(run_transcription)\n",
    "\n",
    "display(transcribe_button)\n",
    "display(HTML(\"<br>\"))\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf70b03",
   "metadata": {},
   "source": [
    "## Step 6: Download Your Transcriptions üì•\n",
    "\n",
    "After transcription is complete, click below to download your files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_output = widgets.Output()\n",
    "\n",
    "def download_transcriptions(b):\n",
    "    with download_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if not transcription_results:\n",
    "            print(\"‚ùå No transcriptions available yet. Please run Step 5 first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"üì• Preparing downloads...\\n\")\n",
    "        \n",
    "        for filename, data in transcription_results.items():\n",
    "            try:\n",
    "                filepath = data['path']\n",
    "                print(f\"   Downloading: {filename}\")\n",
    "                print(f\"   From: {filepath}\")\n",
    "                files.download(filepath)\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Could not download {filename}: {e}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Downloads initiated! Check your browser's download folder.\")\n",
    "\n",
    "def download_all_from_folder(b):\n",
    "    \"\"\"Download all files from the transcriptions folder.\"\"\"\n",
    "    with download_output:\n",
    "        clear_output()\n",
    "        \n",
    "        transcriptions_path = Path(FOLDERS['transcriptions'])\n",
    "        txt_files = list(transcriptions_path.glob('*.txt'))\n",
    "        \n",
    "        if not txt_files:\n",
    "            print(\"‚ùå No transcription files found in the transcriptions folder.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üì• Found {len(txt_files)} file(s) in {FOLDERS['transcriptions']}/\\n\")\n",
    "        \n",
    "        for filepath in txt_files:\n",
    "            try:\n",
    "                print(f\"   Downloading: {filepath.name}\")\n",
    "                files.download(str(filepath))\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Could not download {filepath.name}: {e}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Downloads initiated! Check your browser's download folder.\")\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description='üì• Download Latest Transcriptions',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "download_button.on_click(download_transcriptions)\n",
    "\n",
    "download_all_button = widgets.Button(\n",
    "    description='üì• Download All From Folder',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "download_all_button.on_click(download_all_from_folder)\n",
    "\n",
    "display(widgets.HBox([download_button, download_all_button]))\n",
    "display(HTML(f\"<br><i>üí° All transcriptions are saved in <code>{FOLDERS['transcriptions']}/</code></i>\"))\n",
    "display(download_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661407b5",
   "metadata": {},
   "source": [
    "## Step 7 (Optional): View Transcription Results üëÅÔ∏è\n",
    "\n",
    "Preview your transcription directly in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121afaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_preview_output = widgets.Output()\n",
    "\n",
    "def show_preview(b):\n",
    "    with results_preview_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if not transcription_results:\n",
    "            print(\"‚ùå No transcriptions available yet. Please run Step 5 first.\")\n",
    "            return\n",
    "        \n",
    "        for filename, data in transcription_results.items():\n",
    "            content = data['content']\n",
    "            filepath = data['path']\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"üìÑ {filename}\")\n",
    "            print(f\"üìÅ {filepath}\")\n",
    "            print(\"=\" * 60)\n",
    "            print(content[:5000])  # Show first 5000 characters\n",
    "            if len(content) > 5000:\n",
    "                print(f\"\\n... [Truncated - {len(content) - 5000} more characters]\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "def list_all_transcriptions(b):\n",
    "    \"\"\"List all transcription files in the folder.\"\"\"\n",
    "    with results_preview_output:\n",
    "        clear_output()\n",
    "        \n",
    "        transcriptions_path = Path(FOLDERS['transcriptions'])\n",
    "        txt_files = list(transcriptions_path.glob('*.txt'))\n",
    "        \n",
    "        if not txt_files:\n",
    "            print(\"üìÅ No transcription files found yet.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üìÅ Files in {FOLDERS['transcriptions']}/\\n\")\n",
    "        print(\"-\" * 40)\n",
    "        for filepath in sorted(txt_files):\n",
    "            size_kb = filepath.stat().st_size / 1024\n",
    "            print(f\"   üìÑ {filepath.name} ({size_kb:.1f} KB)\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"\\nTotal: {len(txt_files)} file(s)\")\n",
    "\n",
    "preview_results_button = widgets.Button(\n",
    "    description='üëÅÔ∏è Preview Latest Results',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='200px', height='35px')\n",
    ")\n",
    "preview_results_button.on_click(show_preview)\n",
    "\n",
    "list_files_button = widgets.Button(\n",
    "    description='üìã List All Files',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='150px', height='35px')\n",
    ")\n",
    "list_files_button.on_click(list_all_transcriptions)\n",
    "\n",
    "display(widgets.HBox([preview_results_button, list_files_button]))\n",
    "display(results_preview_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef26aef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ÑπÔ∏è Help & Troubleshooting\n",
    "\n",
    "### üìÅ Folder Structure\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ üìÇ media_files/      ‚Üê Your uploaded audio/video files\n",
    "‚îú‚îÄ‚îÄ üìÇ transcriptions/   ‚Üê Generated transcription outputs\n",
    "‚îú‚îÄ‚îÄ üìÇ prompts/          ‚Üê Editable prompt templates (Markdown)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 1_full_transcription.md\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 2_meeting_minutes.md\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 3_interview.md\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 4_lecture.md\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ 5_qa_summary.md\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ 6_translation.md\n",
    "‚îî‚îÄ‚îÄ üìÇ temp_segments/    ‚Üê Temporary audio segments (auto-cleaned)\n",
    "```\n",
    "\n",
    "### üéµ Supported Audio Formats\n",
    "MP3, WAV, M4A, FLAC, OGG, WEBM, AAC\n",
    "\n",
    "### üé¨ Supported Video Formats  \n",
    "MP4, MOV, AVI, MKV, WEBM\n",
    "\n",
    "### ‚úèÔ∏è Customizing Prompts\n",
    "\n",
    "1. Open the `prompts/` folder in the Colab file browser (left sidebar)\n",
    "2. Double-click any `.md` file to edit it\n",
    "3. Save your changes\n",
    "4. Click **\"üîÑ Reload Prompts\"** in Step 4 to load your edits\n",
    "\n",
    "### ü§ñ Model Selection\n",
    "\n",
    "| Model | Best For | Speed |\n",
    "|-------|----------|-------|\n",
    "| **Gemini 3 Pro** | Complex audio, multiple speakers, challenging accents | Slower |\n",
    "| **Gemini 3 Flash** | Standard recordings, faster processing | Faster |\n",
    "\n",
    "### Common Issues:\n",
    "\n",
    "**\"API key not valid\"**\n",
    "- Make sure you copied the entire API key\n",
    "- Get a new key at: https://aistudio.google.com/app/api-keys\n",
    "\n",
    "**\"File format not supported\"**\n",
    "- Audio: MP3, WAV, M4A, FLAC, OGG, WEBM, AAC\n",
    "- Video: MP4, MOV, AVI, MKV, WEBM\n",
    "- Try converting your file to a supported format\n",
    "\n",
    "**\"Transcription takes too long\"**\n",
    "- Try using \"Gemini 3 Flash\" for faster processing\n",
    "- Enable audio splitting for long audio files\n",
    "- Note: Video files are processed as a single unit\n",
    "\n",
    "**\"Output is not what I expected\"**\n",
    "- Try a different transcription style\n",
    "- Edit the prompt file in the `prompts/` folder\n",
    "- Use the custom prompt option for specific needs\n",
    "\n",
    "**\"Video upload failed\"**\n",
    "- Video files are uploaded to Gemini for processing\n",
    "- Very large videos may take longer to upload and process\n",
    "- Check your internet connection\n",
    "\n",
    "---\n",
    "\n",
    "### About\n",
    "\n",
    "**ZMO AI Pipelines** created by [Fr√©d√©rick Madore](https://www.frederickmadore.com/)\n",
    "\n",
    "Part of the [Leibniz-Zentrum Moderner Orient (ZMO)](https://www.zmo.de/) research tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c1846",
   "metadata": {},
   "source": [
    "## Step 8 (Optional): Cleanup üßπ\n",
    "\n",
    "Delete temporary files or clear everything when you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "cleanup_output = widgets.Output()\n",
    "\n",
    "def cleanup_temp(b):\n",
    "    \"\"\"Delete only temporary segment files.\"\"\"\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        temp_path = Path(FOLDERS['temp'])\n",
    "        if temp_path.exists():\n",
    "            files_deleted = list(temp_path.glob('*'))\n",
    "            for f in files_deleted:\n",
    "                f.unlink()\n",
    "            print(f\"üßπ Deleted {len(files_deleted)} temporary segment file(s)\")\n",
    "        else:\n",
    "            print(\"üìÅ Temp folder is already empty\")\n",
    "\n",
    "def cleanup_media(b):\n",
    "    \"\"\"Delete uploaded media files.\"\"\"\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        media_path = Path(FOLDERS['media'])\n",
    "        if media_path.exists():\n",
    "            files_deleted = list(media_path.glob('*'))\n",
    "            for f in files_deleted:\n",
    "                f.unlink()\n",
    "            print(f\"üßπ Deleted {len(files_deleted)} media file(s)\")\n",
    "            # Clear the uploaded files list\n",
    "            global uploaded_files\n",
    "            uploaded_files = []\n",
    "        else:\n",
    "            print(\"üìÅ Media folder is already empty\")\n",
    "\n",
    "def cleanup_transcriptions(b):\n",
    "    \"\"\"Delete all transcription outputs.\"\"\"\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        trans_path = Path(FOLDERS['transcriptions'])\n",
    "        if trans_path.exists():\n",
    "            files_deleted = list(trans_path.glob('*'))\n",
    "            for f in files_deleted:\n",
    "                f.unlink()\n",
    "            print(f\"üßπ Deleted {len(files_deleted)} transcription file(s)\")\n",
    "            # Clear the results dict\n",
    "            global transcription_results\n",
    "            transcription_results = {}\n",
    "        else:\n",
    "            print(\"üìÅ Transcriptions folder is already empty\")\n",
    "\n",
    "def cleanup_all(b):\n",
    "    \"\"\"Delete everything except prompts.\"\"\"\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        total_deleted = 0\n",
    "        \n",
    "        for folder_name in ['temp', 'media', 'transcriptions']:\n",
    "            folder_path = Path(FOLDERS[folder_name])\n",
    "            if folder_path.exists():\n",
    "                files_deleted = list(folder_path.glob('*'))\n",
    "                for f in files_deleted:\n",
    "                    f.unlink()\n",
    "                total_deleted += len(files_deleted)\n",
    "        \n",
    "        # Clear global state\n",
    "        global uploaded_files, transcription_results\n",
    "        uploaded_files = []\n",
    "        transcription_results = {}\n",
    "        \n",
    "        print(f\"üßπ Deleted {total_deleted} file(s) total\")\n",
    "        print(\"   ‚úÖ Temp segments cleared\")\n",
    "        print(\"   ‚úÖ Media files cleared\")\n",
    "        print(\"   ‚úÖ Transcriptions cleared\")\n",
    "        print(\"   üìÅ Prompts folder preserved\")\n",
    "\n",
    "def show_folder_status(b):\n",
    "    \"\"\"Show current folder contents.\"\"\"\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        print(\"üìä Current folder status:\\n\")\n",
    "        \n",
    "        for folder_name, folder_path in FOLDERS.items():\n",
    "            path = Path(folder_path)\n",
    "            if path.exists():\n",
    "                files = list(path.glob('*'))\n",
    "                total_size = sum(f.stat().st_size for f in files if f.is_file()) / 1024\n",
    "                print(f\"   üìÇ {folder_path}/ : {len(files)} file(s), {total_size:.1f} KB\")\n",
    "            else:\n",
    "                print(f\"   üìÇ {folder_path}/ : (not created)\")\n",
    "\n",
    "# Create buttons\n",
    "btn_temp = widgets.Button(description='üóëÔ∏è Delete Temp Files', button_style='', layout=widgets.Layout(width='180px'))\n",
    "btn_media = widgets.Button(description='üóëÔ∏è Delete Media Files', button_style='warning', layout=widgets.Layout(width='180px'))\n",
    "btn_trans = widgets.Button(description='üóëÔ∏è Delete Transcriptions', button_style='warning', layout=widgets.Layout(width='180px'))\n",
    "btn_all = widgets.Button(description='üóëÔ∏è Delete Everything', button_style='danger', layout=widgets.Layout(width='180px'))\n",
    "btn_status = widgets.Button(description='üìä Show Status', button_style='info', layout=widgets.Layout(width='150px'))\n",
    "\n",
    "btn_temp.on_click(cleanup_temp)\n",
    "btn_media.on_click(cleanup_media)\n",
    "btn_trans.on_click(cleanup_transcriptions)\n",
    "btn_all.on_click(cleanup_all)\n",
    "btn_status.on_click(show_folder_status)\n",
    "\n",
    "display(HTML(\"<b>Safe cleanup:</b>\"))\n",
    "display(widgets.HBox([btn_temp, btn_status]))\n",
    "\n",
    "display(HTML(\"<br><b>‚ö†Ô∏è Careful - these delete your files:</b>\"))\n",
    "display(widgets.HBox([btn_media, btn_trans]))\n",
    "\n",
    "display(HTML(\"<br><b>üî¥ Nuclear option:</b>\"))\n",
    "display(btn_all)\n",
    "display(HTML(\"<i>Note: Prompts folder is always preserved</i>\"))\n",
    "\n",
    "display(HTML(\"<br>\"))\n",
    "display(cleanup_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
