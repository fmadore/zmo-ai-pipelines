{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4106ea6f",
   "metadata": {},
   "source": [
    "## Step 1: Setup (Run this first!) ‚öôÔ∏è\n",
    "\n",
    "Click the ‚ñ∂Ô∏è button to install the required software and setup the environment. This may take a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q google-genai PyPDF2 pandas ipywidgets\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import io\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================\n",
    "# CREATE FOLDER STRUCTURE\n",
    "# ============================================\n",
    "\n",
    "# Define folder paths\n",
    "FOLDERS = {\n",
    "    'pdf': 'pdfs',\n",
    "    'results': 'results',\n",
    "    'prompts': 'prompts',\n",
    "    'log': 'logs'\n",
    "}\n",
    "\n",
    "# Create all folders\n",
    "for folder_name, folder_path in FOLDERS.items():\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# CREATE PROMPT FILES\n",
    "# ============================================\n",
    "\n",
    "PROMPT_CONTENT = {\n",
    "    \"htr_system_prompt_french.md\": \"\"\"# HTR System Prompt for French Handwritten Documents\n",
    "\n",
    "You are a high-precision HTR (Handwritten Text Recognition) system specialized in French-language handwritten documents, engineered to produce research-grade, archival-quality text extraction. Your output directly supports academic research and archival preservation, demanding maximum accuracy and completeness under fair-use principles.\n",
    "\n",
    "## Core Principles\n",
    "\n",
    "1. **Research-Grade Accuracy:** TRANSCRIBE every single word and character from handwritten text with absolute precision ‚Äì zero exceptions. Work character by character, word by word, line by line to minimize Character Error Rate (CER) and Word Error Rate (WER).\n",
    "2. **Historical Authenticity:** PRESERVE the text exactly as written. RETAIN all spelling variations, grammatical structures, syntactic patterns, and punctuation as they appear in the original document. DO NOT normalize, modernize, or correct the historical text.\n",
    "3. **Systematic Zone Analysis:** IDENTIFY and PROCESS distinct content zones in their precise reading order.  \n",
    "4. **Pure Archival Transcription:** DELIVER exact transcription only ‚Äì no summarization, interpretation, or omissions.  \n",
    "5. **Typographic Precision:** ENFORCE French typography rules and formatting guidelines meticulously.  \n",
    "\n",
    "## Detailed Guidelines\n",
    "\n",
    "### 1. Reading Zone Protocol\n",
    "\n",
    "- IDENTIFY distinct reading zones with precision (columns, sidebars, handwritten notes, captions, headers, footers).  \n",
    "- EXECUTE zone processing in strict reading order: left-to-right, top-to-bottom within the main flow.  \n",
    "- PROCESS supplementary zones, including handwritten annotations, systematically after main content.  \n",
    "- MAINTAIN precise relationships between related zones.  \n",
    "\n",
    "### 2. Content Hierarchy Protocol\n",
    "\n",
    "- PROCESS Primary zones: Main body text (handwritten).\n",
    "- PROCESS Secondary zones: Headers, subheaders, bylines.\n",
    "- PROCESS Tertiary zones: Footers, page numbers, marginalia, and handwritten notes.\n",
    "- PROCESS Special zones: Captions, sidebars, boxed content, and handwritten additions.  \n",
    "\n",
    "### 3. Semantic Integration Protocol\n",
    "\n",
    "- MERGE semantically linked lines within the same thought unit.  \n",
    "- DETERMINE paragraph boundaries through semantic analysis.  \n",
    "- PRESERVE logical flow across structural breaks.  \n",
    "- ENFORCE double newline (`\\\\n\\\\n`) between paragraphs.  \n",
    "\n",
    "#### Examples\n",
    "\n",
    "1. **Basic line joining**  \n",
    "   Source: `Le pr√©sident a d√©clar√©\\\\nque la situation s'am√©liore.`  \n",
    "   Required: `Le pr√©sident a d√©clar√© que la situation s'am√©liore.`  \n",
    "\n",
    "2. **Multi-line with hyphens**  \n",
    "   Source:  \n",
    "   ```\n",
    "   Cette rencontre a √©t√©,\n",
    "   par ailleurs, marqu√©e\n",
    "   par des prestations cho-\n",
    "   r√©graphiques des mes-\n",
    "   sagers de Kp√©m√©, des\n",
    "   chants interconfession-\n",
    "   nels, des chorales et de\n",
    "   gospel.\n",
    "   (ATOP)\n",
    "   ```  \n",
    "   Required:  \n",
    "   ```\n",
    "   Cette rencontre a √©t√©, par ailleurs, marqu√©e par des prestations chor√©graphiques des messagers de Kp√©m√©, des chants interconfessionnels, des chorales et de gospel.\n",
    "\n",
    "   (ATOP)\n",
    "   ```\n",
    "\n",
    "3. **Multiple paragraphs**  \n",
    "   Source: `Premier paragraphe.\\\\nSuite du premier.\\\\n\\\\nDeuxi√®me paragraphe.`  \n",
    "   Required: `Premier paragraphe. Suite du premier.\\\\n\\\\nDeuxi√®me paragraphe.`  \n",
    "\n",
    "### 4. Text Processing Protocol\n",
    "\n",
    "- EXECUTE de-hyphenation: remove end-of-line hyphens (e.g. `ana-\\\\nlyse` ‚Üí `analyse`).  \n",
    "- PRESERVE legitimate compound hyphens (e.g. `arc-en-ciel`).  \n",
    "- REPLICATE all diacritical marks and special characters exactly from handwriting.  \n",
    "- IMPLEMENT French spacing rules precisely: ` : `, ` ; `, ` ! `, ` ? `.\n",
    "- RETAIN all original spelling errors, grammatical constructions, and punctuation exactly as written ‚Äî DO NOT correct or modernize.\n",
    "- PRESERVE author's insertions, corrections, and modifications in their indicated positions.  \n",
    "\n",
    "### 5. Special Format Protocol\n",
    "\n",
    "- PRESERVE list hierarchy with exact formatting.  \n",
    "- MAINTAIN table structural integrity completely.  \n",
    "- RETAIN intentional formatting in poetry or special text, handwritten.  \n",
    "- RESPECT spatial relationships in image-caption pairs and handwritten marginalia.  \n",
    "\n",
    "### 6. Quality Control Protocol\n",
    "\n",
    "- PRIORITIZE accuracy over completeness in degraded sections (including unclear handwriting).  \n",
    "- VERIFY semantic flow after line joining.  \n",
    "- ENSURE proper zone separation.  \n",
    "\n",
    "### 7. Self-Review Protocol\n",
    "\n",
    "Examine your initial output against these criteria:  \n",
    "- VERIFY complete transcription of all text zones, including handwritten content.  \n",
    "- CONFIRM accurate reading order and zone relationships.  \n",
    "- CHECK all de-hyphenation and paragraph joining.  \n",
    "- VALIDATE French typography and spacing rules.  \n",
    "- ASSESS semantic flow and coherence.  \n",
    "Correct any deviations before delivering final output.  \n",
    "\n",
    "### 8. Final Formatting Reflection\n",
    "\n",
    "Before delivering your output, pause and verify:  \n",
    "\n",
    "1. **Paragraph structure**  \n",
    "   - Have you joined all lines that belong to the same paragraph?  \n",
    "   - Is there exactly **one** empty line (`\\\\n\\\\n`) between paragraphs?  \n",
    "   - Are there **no** single line breaks within paragraphs?  \n",
    "\n",
    "2. **Hyphenation**  \n",
    "   - Have you removed **all** end-of-line hyphens?  \n",
    "   - Have you properly joined the word parts?  \n",
    "     Example incorrect: `presta-\\\\ntions` ‚Üí should be `prestations`.  \n",
    "     Example correct: `prestations`.  \n",
    "\n",
    "3. **Special elements**  \n",
    "   - Are attributions (e.g. `(ATOP)`) on their own line with double spacing?  \n",
    "   - Are headers and titles properly separated?  \n",
    "\n",
    "4. **Final check**  \n",
    "   - Read your output as continuous text.  \n",
    "   - Verify that every paragraph is a single block of text.  \n",
    "   - Confirm there are no artifacts from the original layout.  \n",
    "   If you find any formatting issues, fix them before final delivery.  \n",
    "\n",
    "## Output Requirements\n",
    "\n",
    "- DELIVER pure transcribed text only.  \n",
    "- EXCLUDE all commentary or explanations.  \n",
    "- MAINTAIN exact French typography standards.  \n",
    "- PRESERVE all semantic and spatial relationships in handwritten additions.\n",
    "\"\"\",\n",
    "    \"htr_system_prompt_arabic.md\": \"\"\"# HTR System Prompt for Arabic Handwritten Manuscripts\n",
    "\n",
    "You are a high-precision HTR (Handwritten Text Recognition) system specialized in Arabic-language handwritten manuscripts, engineered to produce research-grade, archival-quality text extraction. Your output directly supports academic research and archival preservation, demanding maximum accuracy and completeness under fair-use principles.\n",
    "\n",
    "## Core Principles\n",
    "\n",
    "1. **Research-Grade Accuracy:** TRANSCRIBE every single word and character from handwritten Arabic text with absolute precision ‚Äì zero exceptions. Work character by character, word by word, line by line to minimize Character Error Rate (CER) and Word Error Rate (WER).\n",
    "2. **Historical Authenticity:** PRESERVE the text exactly as written. RETAIN all spelling variations, grammatical structures, syntactic patterns, and punctuation as they appear in the original manuscript. DO NOT normalize, modernize, or correct the historical text.\n",
    "3. **Systematic Zone Analysis:** IDENTIFY and PROCESS distinct content zones in their precise reading order.  \n",
    "4. **Pure Archival Transcription:** DELIVER exact transcription only ‚Äì no summarization, interpretation, or omissions.  \n",
    "5. **Typographic Precision:** ENFORCE Arabic typography rules and formatting guidelines meticulously.  \n",
    "\n",
    "## Detailed Guidelines\n",
    "\n",
    "### 1. Reading Zone Protocol\n",
    "\n",
    "- IDENTIFY distinct reading zones with precision (columns, sidebars, handwritten notes, captions, headers, footers, marginalia).  \n",
    "- EXECUTE zone processing in strict reading order: right-to-left for Arabic text, following traditional manuscript layout conventions.  \n",
    "- PROCESS supplementary zones, including handwritten annotations, systematically after main content.  \n",
    "- MAINTAIN precise relationships between related zones.  \n",
    "\n",
    "### 2. Content Hierarchy Protocol\n",
    "\n",
    "- PROCESS Primary zones: Main body text (handwritten Arabic).\n",
    "- PROCESS Secondary zones: Headers, subheaders, chapter titles.\n",
    "- PROCESS Tertiary zones: Footers, page numbers, marginalia, and handwritten notes.\n",
    "- PROCESS Special zones: Captions, sidebars, boxed content, and handwritten additions.  \n",
    "\n",
    "### 3. Semantic Integration Protocol\n",
    "\n",
    "- MERGE semantically linked lines within the same thought unit.  \n",
    "- DETERMINE paragraph boundaries through semantic analysis.  \n",
    "- PRESERVE logical flow across structural breaks.  \n",
    "- ENFORCE double newline (`\\\\n\\\\n`) between paragraphs.  \n",
    "\n",
    "#### Examples\n",
    "\n",
    "1. **Basic line joining**  \n",
    "   Source: `ŸÇÿßŸÑ ÿßŸÑÿ±ÿ¶Ÿäÿ≥\\\\nÿ•ŸÜ ÿßŸÑŸàÿ∂ÿπ Ÿäÿ™ÿ≠ÿ≥ŸÜ.`  \n",
    "   Required: `ŸÇÿßŸÑ ÿßŸÑÿ±ÿ¶Ÿäÿ≥ ÿ•ŸÜ ÿßŸÑŸàÿ∂ÿπ Ÿäÿ™ÿ≠ÿ≥ŸÜ.`  \n",
    "\n",
    "2. **Multiple paragraphs**  \n",
    "   Source: `ÿßŸÑŸÅŸÇÿ±ÿ© ÿßŸÑÿ£ŸàŸÑŸâ.\\\\nÿ™ÿ™ŸÖÿ© ÿßŸÑŸÅŸÇÿ±ÿ©.\\\\n\\\\nÿßŸÑŸÅŸÇÿ±ÿ© ÿßŸÑÿ´ÿßŸÜŸäÿ©.`  \n",
    "   Required: `ÿßŸÑŸÅŸÇÿ±ÿ© ÿßŸÑÿ£ŸàŸÑŸâ. ÿ™ÿ™ŸÖÿ© ÿßŸÑŸÅŸÇÿ±ÿ©.\\\\n\\\\nÿßŸÑŸÅŸÇÿ±ÿ© ÿßŸÑÿ´ÿßŸÜŸäÿ©.`  \n",
    "\n",
    "### 4. Text Processing Protocol\n",
    "\n",
    "- REPLICATE all diacritical marks (tashkeel) and special characters exactly from handwriting when present.  \n",
    "- PRESERVE ligatures and connected letter forms as they appear in the manuscript.  \n",
    "- MAINTAIN proper Arabic spacing rules.  \n",
    "- RESPECT traditional manuscript orthography, including historical spelling variations.\n",
    "- RETAIN all original spelling errors, grammatical constructions, and punctuation exactly as written ‚Äî DO NOT correct or modernize.\n",
    "- PRESERVE author's insertions, corrections, and modifications in their indicated positions.  \n",
    "\n",
    "### 5. Special Format Protocol\n",
    "\n",
    "- PRESERVE list hierarchy with exact formatting.  \n",
    "- MAINTAIN table structural integrity completely.  \n",
    "- RETAIN intentional formatting in poetry, Quranic verses, or special text.  \n",
    "- RESPECT spatial relationships in image-caption pairs and handwritten marginalia.  \n",
    "\n",
    "### 6. Quality Control Protocol\n",
    "\n",
    "- PRIORITIZE accuracy over completeness in degraded sections (including unclear handwriting).  \n",
    "- VERIFY semantic flow after line joining.  \n",
    "- ENSURE proper zone separation.  \n",
    "- MARK uncertain readings with [?] when text is illegible or ambiguous.  \n",
    "\n",
    "### 7. Self-Review Protocol\n",
    "\n",
    "Examine your initial output against these criteria:  \n",
    "- VERIFY complete transcription of all text zones, including handwritten content.  \n",
    "- CONFIRM accurate reading order and zone relationships (right-to-left for Arabic).  \n",
    "- CHECK all paragraph joining and proper line breaks.  \n",
    "- VALIDATE Arabic typography and spacing rules.  \n",
    "- ASSESS semantic flow and coherence.  \n",
    "Correct any deviations before delivering final output.  \n",
    "\n",
    "### 8. Final Formatting Reflection\n",
    "\n",
    "Before delivering your output, pause and verify:  \n",
    "\n",
    "1. **Paragraph structure**  \n",
    "   - Have you joined all lines that belong to the same paragraph?  \n",
    "   - Is there exactly **one** empty line (`\\\\n\\\\n`) between paragraphs?  \n",
    "   - Are there **no** single line breaks within paragraphs?  \n",
    "\n",
    "2. **Arabic text direction**  \n",
    "   - Is the text properly formatted for right-to-left reading?  \n",
    "   - Are numerals and mixed-script elements handled correctly?  \n",
    "\n",
    "3. **Special elements**  \n",
    "   - Are chapter headings and titles properly separated?  \n",
    "   - Are marginalia and annotations clearly distinguished?  \n",
    "\n",
    "4. **Final check**  \n",
    "   - Read your output as continuous text.  \n",
    "   - Verify that every paragraph is a single block of text.  \n",
    "   - Confirm there are no artifacts from the original layout.  \n",
    "   If you find any formatting issues, fix them before final delivery.  \n",
    "\n",
    "## Output Requirements\n",
    "\n",
    "- DELIVER pure transcribed Arabic text only.  \n",
    "- EXCLUDE all commentary or explanations.  \n",
    "- MAINTAIN exact Arabic typography standards.  \n",
    "- PRESERVE all semantic and spatial relationships in handwritten additions.\n",
    "- RESPECT traditional manuscript conventions and historical orthography.\n",
    "\"\"\",\n",
    "    \"htr_system_prompt_multilingual.md\": \"\"\"# HTR System Prompt for Multilingual Handwritten Documents\n",
    "\n",
    "You are a high-precision HTR (Handwritten Text Recognition) system specialized in multilingual handwritten documents, engineered to produce research-grade, archival-quality text extraction. Your output directly supports academic research and archival preservation, demanding maximum accuracy and completeness under fair-use principles.\n",
    "\n",
    "## Core Principles\n",
    "\n",
    "1. **Language Detection First:** IDENTIFY the language(s) and writing system(s) present in the document before transcription.\n",
    "2. **Research-Grade Accuracy:** TRANSCRIBE every single word and character from handwritten text with absolute precision ‚Äì zero exceptions. Work character by character, word by word, line by line to minimize Character Error Rate (CER) and Word Error Rate (WER).\n",
    "3. **Historical Authenticity:** PRESERVE the text exactly as written. RETAIN all spelling variations, grammatical structures, syntactic patterns, and punctuation as they appear in the original document. DO NOT normalize, modernize, or correct the historical text.\n",
    "4. **Systematic Zone Analysis:** IDENTIFY and PROCESS distinct content zones in their precise reading order.  \n",
    "5. **Pure Archival Transcription:** DELIVER exact transcription only ‚Äì no summarization, interpretation, or omissions.  \n",
    "6. **Typographic Precision:** ENFORCE language-specific typography rules and formatting guidelines meticulously.  \n",
    "\n",
    "## Language Detection Protocol\n",
    "\n",
    "### Step 1: Analyze the Document\n",
    "\n",
    "Before transcription, EXAMINE the manuscript and DETERMINE:\n",
    "\n",
    "1. **Primary writing system(s):**\n",
    "   - Latin alphabet (e.g., French, English, Spanish, German, Italian, Portuguese, etc.)\n",
    "   - Arabic script (e.g., Arabic, Persian, Urdu, Ottoman Turkish)\n",
    "   - Cyrillic alphabet (e.g., Russian, Ukrainian, Bulgarian, Serbian)\n",
    "   - Greek alphabet\n",
    "   - Hebrew script\n",
    "   - Chinese characters (Traditional or Simplified)\n",
    "   - Japanese (Hiragana, Katakana, Kanji)\n",
    "   - Korean (Hangul)\n",
    "   - Devanagari script (e.g., Hindi, Sanskrit, Marathi, Nepali)\n",
    "   - Other scripts (Bengali, Tamil, Thai, etc.)\n",
    "\n",
    "2. **Language identification:**\n",
    "   - Examine vocabulary, grammar patterns, and characteristic words\n",
    "   - Note language-specific diacritics and special characters\n",
    "   - Identify any mixed-language sections\n",
    "\n",
    "3. **Text directionality:**\n",
    "   - Left-to-right (most Latin, Cyrillic, Greek scripts)\n",
    "   - Right-to-left (Arabic, Hebrew, Persian)\n",
    "   - Top-to-bottom (traditional Chinese, Japanese)\n",
    "   - Mixed directionality for multilingual documents\n",
    "\n",
    "### Step 2: Output Format\n",
    "\n",
    "BEGIN your transcription with a header (enclosed in square brackets) that states:\n",
    "\n",
    "```\n",
    "[LANGUAGE DETECTED: <language name>]\n",
    "[WRITING SYSTEM: <script name>]\n",
    "[TEXT DIRECTION: <direction>]\n",
    "\n",
    "```\n",
    "\n",
    "Then proceed with the transcription following language-specific rules.\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "```\n",
    "[LANGUAGE DETECTED: Russian]\n",
    "[WRITING SYSTEM: Cyrillic]\n",
    "[TEXT DIRECTION: Left-to-right]\n",
    "\n",
    "<transcribed text follows>\n",
    "```\n",
    "\n",
    "```\n",
    "[LANGUAGE DETECTED: Persian]\n",
    "[WRITING SYSTEM: Arabic script]\n",
    "[TEXT DIRECTION: Right-to-left]\n",
    "\n",
    "<transcribed text follows>\n",
    "```\n",
    "\n",
    "```\n",
    "[LANGUAGE DETECTED: Spanish and Latin (mixed)]\n",
    "[WRITING SYSTEM: Latin alphabet]\n",
    "[TEXT DIRECTION: Left-to-right]\n",
    "\n",
    "<transcribed text follows>\n",
    "```\n",
    "\n",
    "## Detailed Guidelines\n",
    "\n",
    "### 1. Reading Zone Protocol\n",
    "\n",
    "- IDENTIFY distinct reading zones with precision (columns, sidebars, handwritten notes, captions, headers, footers, marginalia).  \n",
    "- EXECUTE zone processing in strict reading order appropriate to the detected language and script.  \n",
    "- PROCESS supplementary zones, including handwritten annotations, systematically after main content.  \n",
    "- MAINTAIN precise relationships between related zones.  \n",
    "\n",
    "### 2. Content Hierarchy Protocol\n",
    "\n",
    "- PROCESS Primary zones: Main body text (handwritten).\n",
    "- PROCESS Secondary zones: Headers, subheaders, titles.\n",
    "- PROCESS Tertiary zones: Footers, page numbers, marginalia, and handwritten notes.\n",
    "- PROCESS Special zones: Captions, sidebars, boxed content, and handwritten additions.  \n",
    "\n",
    "### 3. Semantic Integration Protocol\n",
    "\n",
    "- MERGE semantically linked lines within the same thought unit.  \n",
    "- DETERMINE paragraph boundaries through semantic analysis.  \n",
    "- PRESERVE logical flow across structural breaks.  \n",
    "- ENFORCE double newline (`\\\\n\\\\n`) between paragraphs.  \n",
    "\n",
    "### 4. Language-Specific Text Processing\n",
    "\n",
    "#### For Latin-script languages:\n",
    "- EXECUTE de-hyphenation: remove end-of-line hyphens (e.g., `ana-\\\\nlyse` ‚Üí `analyse`).  \n",
    "- PRESERVE legitimate compound hyphens (e.g., `arc-en-ciel`, `self-aware`).  \n",
    "- REPLICATE all diacritical marks exactly (√©, √±, √∂, ƒÖ, etc.).  \n",
    "- IMPLEMENT language-specific spacing rules (e.g., French: ` : `, ` ; `, ` ! `, ` ? `).\n",
    "- RETAIN all original spelling errors, grammatical constructions, and punctuation exactly as written ‚Äî DO NOT correct or modernize.\n",
    "\n",
    "#### For Arabic script:\n",
    "- REPLICATE all diacritical marks (tashkeel, harakat) when present.  \n",
    "- PRESERVE ligatures and connected letter forms.  \n",
    "- MAINTAIN proper Arabic/Persian spacing rules.  \n",
    "- RESPECT traditional orthography and historical spelling variations.\n",
    "- RETAIN all original spelling errors and grammatical constructions exactly as written ‚Äî DO NOT correct or modernize.\n",
    "\n",
    "#### For Cyrillic script:\n",
    "- PRESERVE hard signs (—ä), soft signs (—å), and all special characters (—ë, —î, —ñ, —ó, etc.).  \n",
    "- REPLICATE historical orthographic forms if present (pre-reform spellings).  \n",
    "- MAINTAIN proper spacing and punctuation rules.\n",
    "- RETAIN all original spelling errors and grammatical constructions exactly as written ‚Äî DO NOT correct or modernize.\n",
    "\n",
    "#### For East Asian scripts:\n",
    "- PRESERVE traditional or simplified character forms as written.  \n",
    "- MAINTAIN proper spacing between characters and punctuation.  \n",
    "- RESPECT vertical or horizontal text orientation as present.  \n",
    "- PRESERVE ruby annotations (furigana) if present.\n",
    "- RETAIN all original character choices and grammatical constructions exactly as written ‚Äî DO NOT correct or modernize.\n",
    "\n",
    "#### For Other scripts:\n",
    "- IDENTIFY and use the correct Unicode characters for the script.  \n",
    "- PRESERVE all diacritics, vowel marks, and special characters.  \n",
    "- MAINTAIN script-specific spacing and formatting conventions.\n",
    "- RETAIN all original spelling errors and grammatical constructions exactly as written ‚Äî DO NOT correct or modernize.\n",
    "\n",
    "#### Universal requirement for all scripts:\n",
    "- PRESERVE author's insertions, corrections, and modifications in their indicated positions.  \n",
    "\n",
    "### 5. Special Format Protocol\n",
    "\n",
    "- PRESERVE list hierarchy with exact formatting.  \n",
    "- MAINTAIN table structural integrity completely.  \n",
    "- RETAIN intentional formatting in poetry, religious texts, or special content.  \n",
    "- RESPECT spatial relationships in image-caption pairs and handwritten marginalia.  \n",
    "\n",
    "### 6. Quality Control Protocol\n",
    "\n",
    "- PRIORITIZE accuracy over completeness in degraded sections (including unclear handwriting).  \n",
    "- VERIFY semantic flow after line joining.  \n",
    "- ENSURE proper zone separation.  \n",
    "- MARK uncertain readings with [?] when text is illegible or ambiguous.  \n",
    "- NOTE language switches with [LANGUAGE SWITCH: <new language>] if the document contains multiple languages.\n",
    "\n",
    "### 7. Self-Review Protocol\n",
    "\n",
    "Examine your initial output against these criteria:  \n",
    "- VERIFY correct language and script identification.\n",
    "- CONFIRM complete transcription of all text zones, including handwritten content.  \n",
    "- VALIDATE accurate reading order and zone relationships for the detected script direction.  \n",
    "- CHECK all language-specific processing (hyphenation, diacritics, spacing).  \n",
    "- ASSESS semantic flow and coherence.  \n",
    "Correct any deviations before delivering final output.  \n",
    "\n",
    "### 8. Final Formatting Reflection\n",
    "\n",
    "Before delivering your output, pause and verify:  \n",
    "\n",
    "1. **Language detection header**  \n",
    "   - Have you included the language detection header at the beginning?  \n",
    "   - Is the detected language, writing system, and direction correct?  \n",
    "\n",
    "2. **Paragraph structure**  \n",
    "   - Have you joined all lines that belong to the same paragraph?  \n",
    "   - Is there exactly **one** empty line (`\\\\n\\\\n`) between paragraphs?  \n",
    "   - Are there **no** single line breaks within paragraphs?  \n",
    "\n",
    "3. **Language-specific rules**  \n",
    "   - Have you applied the correct typography rules for the detected language?  \n",
    "   - Are diacritics and special characters properly rendered?  \n",
    "   - Is the text direction respected in formatting?  \n",
    "\n",
    "4. **Mixed-language handling**  \n",
    "   - Are language switches clearly marked if present?  \n",
    "   - Is each section transcribed according to its own language rules?  \n",
    "\n",
    "5. **Final check**  \n",
    "   - Read your output as continuous text.  \n",
    "   - Verify that every paragraph is a single block of text.  \n",
    "   - Confirm there are no artifacts from the original layout.  \n",
    "   If you find any formatting issues, fix them before final delivery.  \n",
    "\n",
    "## Output Requirements\n",
    "\n",
    "- BEGIN with language detection header in square brackets.\n",
    "- DELIVER pure transcribed text only (after the header).  \n",
    "- EXCLUDE all commentary or explanations beyond the detection header.  \n",
    "- MAINTAIN exact language-specific typography standards.  \n",
    "- PRESERVE all semantic and spatial relationships in handwritten additions.\n",
    "- RESPECT traditional manuscript conventions and historical orthography for all languages.\n",
    "- USE correct Unicode characters for all scripts and special characters.\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Write prompt files to disk\n",
    "for filename, content in PROMPT_CONTENT.items():\n",
    "    filepath = os.path.join(FOLDERS['prompts'], filename)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print()\n",
    "print(\"üìÅ Folder structure created:\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ üìÇ pdfs/             ‚Üê Upload your PDF files here\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ üìÇ results/          ‚Üê Output text files saved here\")\n",
    "print(\"   ‚îú‚îÄ‚îÄ üìÇ prompts/          ‚Üê System prompts\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ htr_system_prompt_french.md\")\n",
    "print(\"   ‚îÇ   ‚îú‚îÄ‚îÄ htr_system_prompt_arabic.md\")\n",
    "print(\"   ‚îÇ   ‚îî‚îÄ‚îÄ htr_system_prompt_multilingual.md\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ üìÇ logs/             ‚Üê Processing logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef6f2b",
   "metadata": {},
   "source": [
    "## Step 2: Enter Your API Key üîë\n",
    "\n",
    "Enter your Google Gemini API key below. \n",
    "\n",
    "**Don't have one?** Get it free at: https://aistudio.google.com/app/api-keys\n",
    "\n",
    "Your API key is entered securely (hidden like a password)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0de1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a secure password field for the API key\n",
    "api_key_input = widgets.Password(\n",
    "    placeholder='Paste your API key here',\n",
    "    description='API Key:',\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    style={'description_width': '80px'}\n",
    ")\n",
    "\n",
    "api_key_status = widgets.HTML(value=\"\")\n",
    "\n",
    "def validate_api_key(change):\n",
    "    if len(change['new']) > 20:\n",
    "        api_key_status.value = \"<span style='color: green;'>‚úÖ API key entered</span>\"\n",
    "    else:\n",
    "        api_key_status.value = \"<span style='color: orange;'>‚è≥ Please enter your full API key</span>\"\n",
    "\n",
    "api_key_input.observe(validate_api_key, names='value')\n",
    "\n",
    "display(HTML(\"<b>Enter your Gemini API key:</b>\"))\n",
    "display(api_key_input)\n",
    "display(api_key_status)\n",
    "display(HTML(\"<br><i>üí° Tip: Your key starts with 'AIza...'</i>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fecc73",
   "metadata": {},
   "source": [
    "## Step 3: Upload Your PDF Documents üìÅ\n",
    "\n",
    "Click the button below to select and upload your PDF files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store uploaded files\n",
    "uploaded_files = []\n",
    "\n",
    "upload_status = widgets.HTML(value=\"\")\n",
    "\n",
    "def upload_pdf_files(b):\n",
    "    global uploaded_files\n",
    "    upload_status.value = \"<span style='color: blue;'>üì§ Upload dialog opened... Select your PDF file(s)</span>\"\n",
    "    \n",
    "    try:\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if uploaded:\n",
    "            uploaded_files = []\n",
    "            valid_files = []\n",
    "            invalid_files = []\n",
    "            \n",
    "            for filename, content in uploaded.items():\n",
    "                ext = Path(filename).suffix.lower()\n",
    "                if ext == '.pdf':\n",
    "                    # Save file to pdfs folder\n",
    "                    filepath = os.path.join(FOLDERS['pdf'], filename)\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        f.write(content)\n",
    "                    uploaded_files.append(filepath)\n",
    "                    valid_files.append(filename)\n",
    "                else:\n",
    "                    invalid_files.append(filename)\n",
    "            \n",
    "            status_html = \"\"\n",
    "            if valid_files:\n",
    "                status_html += f\"<span style='color: green;'>‚úÖ Uploaded {len(valid_files)} PDF file(s) to <code>pdfs/</code>:</span><br>\"\n",
    "                for f in valid_files:\n",
    "                    status_html += f\"&nbsp;&nbsp;&nbsp;üìÑ {f}<br>\"\n",
    "            if invalid_files:\n",
    "                status_html += f\"<span style='color: red;'>‚ùå Skipped {len(invalid_files)} non-PDF file(s):</span><br>\"\n",
    "                for f in invalid_files:\n",
    "                    status_html += f\"&nbsp;&nbsp;&nbsp;‚ö†Ô∏è {f}<br>\"\n",
    "            \n",
    "            upload_status.value = status_html\n",
    "        else:\n",
    "            upload_status.value = \"<span style='color: orange;'>‚ö†Ô∏è No files uploaded</span>\"\n",
    "    except Exception as e:\n",
    "        upload_status.value = f\"<span style='color: red;'>‚ùå Error: {str(e)}</span>\"\n",
    "\n",
    "upload_button = widgets.Button(\n",
    "    description='üìÅ Click to Upload PDF Files',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "upload_button.on_click(upload_pdf_files)\n",
    "\n",
    "display(upload_button)\n",
    "display(upload_status)\n",
    "display(HTML(\"<br><i>üí° Files will be saved to the <code>pdfs/</code> folder</i>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5fd9da",
   "metadata": {},
   "source": [
    "## Step 4: HTR Settings üéõÔ∏è\n",
    "\n",
    "Select the AI model and manuscript language.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90777804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SETTINGS WIDGETS\n",
    "# ============================================\n",
    "\n",
    "# Model selection\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Gemini 3.0 Pro (Latest, highest quality)', 'gemini-3-pro-preview'),\n",
    "        ('Gemini 2.5 Pro (High quality, balanced)', 'gemini-2.5-pro'),\n",
    "        ('Gemini 2.5 Flash (Faster, good quality)', 'gemini-2.5-flash'),\n",
    "    ],\n",
    "    value='gemini-3-pro-preview',\n",
    "    description='AI Model:',\n",
    "    style={'description_width': '100px'},\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "# Language selection\n",
    "language_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('French Handwritten Manuscripts', 'french'),\n",
    "        ('Arabic Handwritten Manuscripts', 'arabic'),\n",
    "        ('Multilingual / Auto-detect', 'multilingual'),\n",
    "    ],\n",
    "    value='french',\n",
    "    description='Language:',\n",
    "    style={'description_width': '100px'},\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "# Thinking budget info\n",
    "thinking_info = widgets.HTML(value=\"\")\n",
    "\n",
    "def update_thinking_info(change):\n",
    "    model = change['new']\n",
    "    if \"pro\" in model:\n",
    "        thinking_info.value = \"<i>üß† Thinking mode enabled (Budget: 128 tokens)</i>\"\n",
    "    else:\n",
    "        thinking_info.value = \"<i>üß† Thinking mode disabled (Flash model)</i>\"\n",
    "\n",
    "model_dropdown.observe(update_thinking_info, names='value')\n",
    "# Initialize\n",
    "update_thinking_info({'new': model_dropdown.value})\n",
    "\n",
    "display(HTML(\"<h3>ü§ñ Select AI Model</h3>\"))\n",
    "display(model_dropdown)\n",
    "display(thinking_info)\n",
    "\n",
    "display(HTML(\"<h3>üìú Select Manuscript Language</h3>\"))\n",
    "display(language_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a80c92",
   "metadata": {},
   "source": [
    "## Step 5: Start HTR Processing üöÄ\n",
    "\n",
    "Click the button below to start processing your PDF file(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a405e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# HTR ENGINE\n",
    "# ============================================\n",
    "\n",
    "class ColabGeminiHTR:\n",
    "    \"\"\"\n",
    "    A high-precision HTR system using Google's Gemini model with native PDF processing.\n",
    "    Adapted for Google Colab environment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model_name: str, language: str = \"french\"):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.model_name = model_name\n",
    "        self.language = language\n",
    "        self.generation_config = self._setup_generation_config()\n",
    "        \n",
    "    def _setup_generation_config(self):\n",
    "        # Set thinking budget based on model capabilities\n",
    "        if \"2.5-pro\" in self.model_name.lower() or \"3-pro\" in self.model_name.lower():\n",
    "            thinking_budget = 128\n",
    "        else:\n",
    "            thinking_budget = 0\n",
    "        \n",
    "        return types.GenerateContentConfig(\n",
    "            temperature=0.2,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "            max_output_tokens=65535,\n",
    "            response_mime_type=\"text/plain\",\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=thinking_budget),\n",
    "            safety_settings=[\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "                ),\n",
    "                types.SafetySetting(\n",
    "                    category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "                    threshold=types.HarmBlockThreshold.BLOCK_NONE\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def _get_system_instruction(self):\n",
    "        # Select the appropriate prompt file based on language\n",
    "        if self.language == \"arabic\":\n",
    "            filename = \"htr_system_prompt_arabic.md\"\n",
    "        elif self.language == \"multilingual\":\n",
    "            filename = \"htr_system_prompt_multilingual.md\"\n",
    "        else:  # default to french\n",
    "            filename = \"htr_system_prompt_french.md\"\n",
    "        \n",
    "        prompt_file = os.path.join(FOLDERS['prompts'], filename)\n",
    "        \n",
    "        try:\n",
    "            with open(prompt_file, 'r', encoding='utf-8') as f:\n",
    "                return f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading system prompt file: {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_pdf_page(self, pdf_path, page_number):\n",
    "        try:\n",
    "            reader = PdfReader(str(pdf_path))\n",
    "            writer = PdfWriter()\n",
    "            writer.add_page(reader.pages[page_number])\n",
    "            output_buffer = io.BytesIO()\n",
    "            writer.write(output_buffer)\n",
    "            output_buffer.seek(0)\n",
    "            return output_buffer.getvalue()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error extracting page {page_number + 1}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_pdf_page_count(self, pdf_path):\n",
    "        try:\n",
    "            reader = PdfReader(str(pdf_path))\n",
    "            return len(reader.pages)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading PDF page count: {e}\")\n",
    "            raise\n",
    "\n",
    "    def process_pdf_page(self, page_bytes, page_num):\n",
    "        \"\"\"Process a single PDF page (inline only for Colab simplicity).\"\"\"\n",
    "        try:\n",
    "            print(f\"   ‚îî‚îÄ üìÑ Processing page {page_num}...\")\n",
    "            \n",
    "            pdf_part = types.Part.from_bytes(\n",
    "                data=page_bytes,\n",
    "                mime_type='application/pdf'\n",
    "            )\n",
    "            \n",
    "            if self.language == \"multilingual\":\n",
    "                language_desc = \"text (detect language automatically)\"\n",
    "            elif self.language == \"arabic\":\n",
    "                language_desc = \"Arabic\"\n",
    "            else:\n",
    "                language_desc = \"French\"\n",
    "            \n",
    "            combined_prompt = (\n",
    "                self._get_system_instruction() + \"\\n\\n\" +\n",
    "                f\"This is a legitimate handwritten text transcription (HTR) request for academic research and archival preservation. \"\n",
    "                f\"Transcribe ALL handwritten {language_desc} text with exact wording, spacing rules, accents, and WITHOUT summarizing or omitting any zones.\"\n",
    "            )\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model_name,\n",
    "                contents=[pdf_part, combined_prompt],\n",
    "                config=self.generation_config\n",
    "            )\n",
    "            \n",
    "            if not response.candidates:\n",
    "                raise Exception(\"No candidates in Gemini response\")\n",
    "            \n",
    "            candidate = response.candidates[0]\n",
    "            if not candidate.content or not candidate.content.parts:\n",
    "                 raise Exception(f\"No valid response. Finish reason: {candidate.finish_reason}\")\n",
    "\n",
    "            text_content = response.text.replace('\\xa0', ' ').strip()\n",
    "            if not text_content:\n",
    "                raise Exception(\"Empty text response\")\n",
    "            \n",
    "            print(f\"   ‚îî‚îÄ ‚úÖ Page {page_num} complete\")\n",
    "            return text_content\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚îî‚îÄ ‚ùå Page {page_num} failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# ============================================\n",
    "# PROCESSING BUTTON AND OUTPUT\n",
    "# ============================================\n",
    "\n",
    "htr_output_area = widgets.Output()\n",
    "htr_results = {}  # Store results for download\n",
    "\n",
    "def run_htr_process(b):\n",
    "    global htr_results\n",
    "    htr_results = {}\n",
    "    \n",
    "    with htr_output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        # Validate inputs\n",
    "        if not api_key_input.value or len(api_key_input.value) < 20:\n",
    "            print(\"‚ùå Please enter a valid API key in Step 2\")\n",
    "            return\n",
    "        \n",
    "        if not uploaded_files:\n",
    "            print(\"‚ùå Please upload at least one PDF file in Step 3\")\n",
    "            return\n",
    "        \n",
    "        # Get settings\n",
    "        api_key = api_key_input.value\n",
    "        model = model_dropdown.value\n",
    "        language = language_dropdown.value\n",
    "        \n",
    "        print(f\"ü§ñ Model: {model}\")\n",
    "        print(f\"üìú Language: {language}\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            # Initialize HTR\n",
    "            htr = ColabGeminiHTR(api_key, model, language)\n",
    "            print(\"‚úÖ Connected to Gemini API\\n\")\n",
    "            \n",
    "            # Process each file\n",
    "            for i, pdf_file in enumerate(uploaded_files, 1):\n",
    "                filename = Path(pdf_file).name\n",
    "                print(f\"\\nüìö Processing PDF {i}/{len(uploaded_files)}: {filename}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                try:\n",
    "                    total_pages = htr.get_pdf_page_count(pdf_file)\n",
    "                    print(f\"   üìÑ Found {total_pages} pages\")\n",
    "                    \n",
    "                    full_text = []\n",
    "                    successful_pages = 0\n",
    "                    \n",
    "                    for page_idx in range(total_pages):\n",
    "                        page_num = page_idx + 1\n",
    "                        \n",
    "                        # Extract page\n",
    "                        page_bytes = htr.extract_pdf_page(pdf_file, page_idx)\n",
    "                        \n",
    "                        # Process page\n",
    "                        text = htr.process_pdf_page(page_bytes, page_num)\n",
    "                        \n",
    "                        if text:\n",
    "                            if page_num == 1:\n",
    "                                full_text.append(text)\n",
    "                            else:\n",
    "                                full_text.append(f\"\\n\\n--- Page {page_num} ---\\n\\n{text}\")\n",
    "                            successful_pages += 1\n",
    "                        else:\n",
    "                            error_msg = f\"[ERROR: Failed to process page {page_num}]\"\n",
    "                            if page_num == 1:\n",
    "                                full_text.append(error_msg)\n",
    "                            else:\n",
    "                                full_text.append(f\"\\n\\n--- Page {page_num} ---\\n\\n{error_msg}\")\n",
    "                    \n",
    "                    # Save result\n",
    "                    final_text = \"\".join(full_text)\n",
    "                    output_filename = Path(pdf_file).stem + \"_htr.txt\"\n",
    "                    output_path = os.path.join(FOLDERS['results'], output_filename)\n",
    "                    \n",
    "                    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(f\"HTR of: {filename}\\n\")\n",
    "                        f.write(f\"Model: {model}\\n\")\n",
    "                        f.write(f\"Language: {language}\\n\")\n",
    "                        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "                        f.write(final_text)\n",
    "                    \n",
    "                    htr_results[output_filename] = {\n",
    "                        'path': output_path\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"\\n‚úÖ PDF complete! ({successful_pages}/{total_pages} pages)\")\n",
    "                    print(f\"   üìÑ Saved to: {output_path}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ùå Error processing {filename}: {str(e)}\")\n",
    "            \n",
    "            # Summary\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"üéâ HTR PROCESSING COMPLETE!\")\n",
    "            print(f\"   Files processed: {len(htr_results)}\")\n",
    "            print(f\"   üìÅ Output folder: {FOLDERS['results']}/\")\n",
    "            print(\"\\nüëá Download your results in the next step\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "\n",
    "htr_button = widgets.Button(\n",
    "    description='üöÄ Start HTR Processing',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='50px')\n",
    ")\n",
    "htr_button.on_click(run_htr_process)\n",
    "\n",
    "display(htr_button)\n",
    "display(HTML(\"<br>\"))\n",
    "display(htr_output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab901a86",
   "metadata": {},
   "source": [
    "## Step 6: Download Your Results üì•\n",
    "\n",
    "After processing is complete, click below to download your text files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02722d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_output = widgets.Output()\n",
    "\n",
    "def download_results(b):\n",
    "    with download_output:\n",
    "        clear_output()\n",
    "        \n",
    "        if not htr_results:\n",
    "            print(\"‚ùå No results available yet. Please run Step 5 first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"üì• Preparing downloads...\\n\")\n",
    "        \n",
    "        for filename, data in htr_results.items():\n",
    "            try:\n",
    "                filepath = data['path']\n",
    "                print(f\"   Downloading: {filename}\")\n",
    "                files.download(filepath)\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è Could not download {filename}: {e}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Downloads initiated! Check your browser's download folder.\")\n",
    "\n",
    "def download_all_zip(b):\n",
    "    \"\"\"Zip and download all results.\"\"\"\n",
    "    with download_output:\n",
    "        clear_output()\n",
    "        \n",
    "        results_path = Path(FOLDERS['results'])\n",
    "        txt_files = list(results_path.glob('*.txt'))\n",
    "        \n",
    "        if not txt_files:\n",
    "            print(\"‚ùå No result files found.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üì¶ Zipping {len(txt_files)} file(s)...\")\n",
    "        shutil.make_archive('htr_results', 'zip', results_path)\n",
    "        \n",
    "        print(\"üì• Downloading zip file...\")\n",
    "        files.download('htr_results.zip')\n",
    "        print(\"\\n‚úÖ Download initiated!\")\n",
    "\n",
    "download_button = widgets.Button(\n",
    "    description='üì• Download Latest Results',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "download_button.on_click(download_results)\n",
    "\n",
    "download_zip_button = widgets.Button(\n",
    "    description='üì¶ Download All as ZIP',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='250px', height='40px')\n",
    ")\n",
    "download_zip_button.on_click(download_all_zip)\n",
    "\n",
    "display(widgets.HBox([download_button, download_zip_button]))\n",
    "display(HTML(f\"<br><i>üí° All results are saved in <code>{FOLDERS['results']}/</code></i>\"))\n",
    "display(download_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910f730",
   "metadata": {},
   "source": [
    "## Step 7: Cleanup üßπ\n",
    "\n",
    "Delete temporary files or clear everything when you're done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_output = widgets.Output()\n",
    "\n",
    "def cleanup_pdfs(b):\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        path = Path(FOLDERS['pdf'])\n",
    "        if path.exists():\n",
    "            files_deleted = list(path.glob('*'))\n",
    "            for f in files_deleted:\n",
    "                f.unlink()\n",
    "            print(f\"üßπ Deleted {len(files_deleted)} PDF file(s)\")\n",
    "            global uploaded_files\n",
    "            uploaded_files = []\n",
    "        else:\n",
    "            print(\"üìÅ PDF folder is already empty\")\n",
    "\n",
    "def cleanup_results(b):\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        path = Path(FOLDERS['results'])\n",
    "        if path.exists():\n",
    "            files_deleted = list(path.glob('*'))\n",
    "            for f in files_deleted:\n",
    "                f.unlink()\n",
    "            print(f\"üßπ Deleted {len(files_deleted)} result file(s)\")\n",
    "            global htr_results\n",
    "            htr_results = {}\n",
    "        else:\n",
    "            print(\"üìÅ Results folder is already empty\")\n",
    "\n",
    "def cleanup_all(b):\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        cleanup_pdfs(None)\n",
    "        cleanup_results(None)\n",
    "        print(\"‚ú® All temporary files cleared!\")\n",
    "\n",
    "btn_pdf = widgets.Button(description='üóëÔ∏è Delete PDFs', button_style='warning', layout=widgets.Layout(width='180px'))\n",
    "btn_res = widgets.Button(description='üóëÔ∏è Delete Results', button_style='warning', layout=widgets.Layout(width='180px'))\n",
    "btn_all = widgets.Button(description='üóëÔ∏è Delete Everything', button_style='danger', layout=widgets.Layout(width='180px'))\n",
    "\n",
    "btn_pdf.on_click(cleanup_pdfs)\n",
    "btn_res.on_click(cleanup_results)\n",
    "btn_all.on_click(cleanup_all)\n",
    "\n",
    "display(HTML(\"<b>Cleanup options:</b>\"))\n",
    "display(widgets.HBox([btn_pdf, btn_res, btn_all]))\n",
    "display(cleanup_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
